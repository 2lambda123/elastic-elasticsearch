index :
  analysis :
    tokenizer :
      my_standard_tokenizer :
        type : standard
    filter :
      stop1 :
        type : stop
        stopwords : [test-stop]
      stop2 :
        type : stop
        stopwords : [stop2-1, stop2-2]
      my :
        type : myfilter
      dict_dec :
        type : dictionary_decompounder
        word_list : [donau, dampf, schiff, spargel, creme, suppe]
    analyzer :
      my_standard :
        type : standard
        stopwords : [test1, test2, test3]
      custom1 :
        tokenizer : my_standard_tokenizer
        filter : [stop1, stop2]
      custom4 :
        tokenizer : my_standard_tokenizer
        filter : [my]
      custom6 :
        tokenizer : my_standard_tokenizer
        position_increment_gap: 256
      custom7 :
        type : standard
        version: 3.6
      czechAnalyzerWithStemmer :
        tokenizer : my_standard_tokenizer
        filter : [lowercase, stop1, czech_stem]
      decompoundingAnalyzer :
        tokenizer : my_standard_tokenizer
        filter : [dict_dec]
