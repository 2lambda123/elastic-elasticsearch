[[rrf]]
=== Reciprocal rank fusion

NOTE: Reciprocal rank fusion requires a Platinum subscription or higher.

IMPORTANT: Reciprocal rank fusion is in technical preview. Features in technical
preview may be changed or removed in a future release. Elastic will apply best
effort to fix any issues, but features in technical preview are not subject to
the support SLA of official GA features.

Reciprocal rank fusion (RRF) is a method for combining results from
multiple queries with different relevance indicators into a single
result set where there is no requirement the relevance indicators for
each query are related to each other in order to achieve high-quality results.

RRF uses the following formula to determine the score for ranking each document:

[source,python]
----
score = 0.0
for q in queries:
    if d in result(q):
        score += 1.0 / ( k + rank( result(q), d ) )
return score

# where
# k is a ranking constant
# q is a query in the set of queries
# d is a document in the result set of q
# result(q) is the result set of q
# rank( result(q), d ) is d's rank within the result(q) starting from 1
----
// NOTCONSOLE

[[rrf-api]]
==== Reciprocal rank fusion API

RRF may be used as part of a <<search-search, search>> to combine and rank
documents using either a single standard query and 1-to-many knn searches or no standard
query and 2-to-many knn searches. The `rrf` parameter is an optional object defined as part
of a search request's <<request-body-rank, rank parameter>>.

The `rrf` object contains the following parameters:

`rank_constant`::
(Optional, integer) This value determines how much influence documents in individual
result sets per query have over the final ranked result set. A higher value indicates
that lower ranked documents have more influence. This value must be greater than or
equal to `1`. Defaults to `60`.

`window_size`::
(Optional, integer) This value determines the size of the individual results sets per
query. A higher value will improve result relevance at the cost of performance. The final
ranked result set is pruned down to the search request's <<search-api-query-params-q, size>.
`window_size` must be greater than or equal to `size` and greater than or equal to `1`.
Defaults to `100`.

An example request using RRF:

[source,console]
----
GET rrf-index/_search
{
    "query": {                       <1>
        "term": {
            "rrf_text": "shoes"
        }
    },
    "knn": {                         <2>
        "field": "rrf-vector",
        "query_vector": [1.25, 2, 3.5],
        "k": 50,
        "num_candidates": 100
    },
    "rank": {                        <3>
        "rrf": {                     <4>
            "window_size": 50,       <5>
            "rank_constant": 20      <6>
        }
    }
}
----
// TEST[skip:example fragment]
<1> a standard query
<2> a knn search
<3> the `rank` object
<4> the `rrf` object
<5> the `window_size` set to `50`
<6> the `rank_constant` set to `20`

The above example uses RRF to combine and rank the standard query and knn search.

[[rrf-supported-features]]
==== Reciprocal rank fusion supported features

RRF does support:

* from
* aggregations

RRF does not support:

* scrolling
* point in time queries
* sorting
* rescoring
* suggestions
* highlighting
* collapsable fields
* explain
* profile

[[rrf-full-example]]
==== Reciprocal rank fusion full example

We begin by creating a mapping for an rrf-index with a text field, a vector field,
and an integer field along with indexing several documents. For this example we
are going to use a vector with only a single dimension to make the ranking easier
to explain.

[source,console]
----
PUT rrf-index
{
  "mappings": {
        "properties": {
            "rrf_text" : {
                "type" : "text"
            },
            "rrf_vector": {
                "type": "dense_vector",
                "dims": 1,
                "index": true,
                "similarity": "l2_norm"
            },
            "rrf_integer" : {
                "type" : "integer"
            }
        }
    }
}

PUT rrf-index/_doc/1
{
    "rrf_text" : "rrf",
    "rrf_vector" : [5],
    "rrf_integer": 1
}

PUT rrf-index/_doc/2
{
    "rrf_text" : "rrf rrf",
    "rrf_vector" : [4],
    "rrf_integer": 2
}

PUT rrf-index/_doc/3
{
    "rrf_text" : "rrf rrf rrf",
    "rrf_vector" : [3],
    "rrf_integer": 1
}

PUT rrf-index/_doc/4
{
    "rrf_text" : "rrf rrf rrf rrf",
    "rrf_integer": 2
}

PUT rrf-index/_doc/5
{
    "rrf_vector" : [1],
    "rrf_integer": 1
}

POST rrf-index/_refresh
----
// TEST

We now execute a search using RRF with a standard query, a knn search, and
a terms aggregation.

[source,console]
----
GET rrf-index/_search
{
    "query": {
        "term": {
            "rrf_text": "rrf"
        }
    },
    "knn": {
        "field": "rrf_vector",
        "query_vector": [3],
        "k": 5,
        "num_candidates": 5
    },
    "rank": {
        "rrf": {
            "window_size": 5,
            "rank_constant": 1
        }
    },
    "size": 3,
    "aggs": {
        "rrf_int_count": {
            "terms": {
                "field": "rrf_integer"
            }
        }
    }
}
----
// TEST[continued]

And we receive the response with ranked `hits` and the
terms aggregation result. Note that `_score` is replaced by
`_rank`.

[source,console-response]
----
{
    "took": ...,
    "timed_out" : false,
    "_shards" : {
        "total" : 1,
        "successful" : 1,
        "skipped" : 0,
        "failed" : 0
    },
    "hits" : {
        "total" : {
            "value" : 5,
            "relation" : "eq"
        },
        "max_score" : null,
        "hits" : [
            {
                "_index" : "rrf-index",
                "_id" : "3",
                "_score" : null,
                "_rank" : 1,
                "_source" : {
                    "rrf_integer" : 1,
                    "rrf_vector" : [
                        3
                    ],
                    "rrf_text" : "rrf rrf rrf"
                }
            },
            {
                "_index" : "rrf-index",
                "_id" : "2",
                "_score" : null,
                "_rank" : 2,
                "_source" : {
                    "rrf_integer" : 2,
                    "rrf_vector" : [
                        4
                    ],
                    "rrf_text" : "rrf rrf"
                }
            },
            {
                "_index" : "rrf-index",
                "_id" : "4",
                "_score" : null,
                "_rank" : 3,
                "_source" : {
                    "rrf_integer" : 2,
                    "rrf_text" : "rrf rrf rrf rrf"
                }
            }
        ]
    },
    "aggregations" : {
        "rrf_int_count" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets" : [
                {
                    "key" : 1,
                    "doc_count" : 3
                },
                {
                    "key" : 2,
                    "doc_count" : 2
                }
            ]
        }
    }
}
----
// TESTRESPONSE[s/: \.\.\./: $body.$_path/]

Let's break down how these hits were ranked. We
start by running the standard query and knn search
separately to collect what their individual hits are.

First, we look at the hits for the standard query.

[source,console-result]
----
"hits" : [
    {
        "_index" : "rrf-index",
        "_id" : "4",
        "_score" : 0.16152832,              <1>
        "_source" : {
            "rrf_integer" : 2,
            "rrf_text" : "rrf rrf rrf rrf"
        }
    },
    {
        "_index" : "rrf-index",
        "_id" : "3",                        <2>
        "_score" : 0.15876243,
        "_source" : {
            "rrf_integer" : 1,
            "rrf_vector" : [3],
            "rrf_text" : "rrf rrf rrf"
        }
    },
    {
        "_index" : "rrf-index",
        "_id" : "2",                        <3>
        "_score" : 0.15350538,
        "_source" : {
            "rrf_integer" : 2,
            "rrf_vector" : [4],
            "rrf_text" : "rrf rrf"
        }
    },
    {
        "_index" : "rrf-index",
        "_id" : "1",                        <4>
        "_score" : 0.13963442,
        "_source" : {
            "rrf_integer" : 1,
            "rrf_vector" : [5],
            "rrf_text" : "rrf"
        }
    }
]
----
// TEST[skip:example fragment]
<1> rank 1, `_id` 4
<2> rank 2, `_id` 3
<3> rank 3, `_id` 2
<4> rank 4, `_id` 1

Note that our first hit doesn't have a value for the `rrf_vector` field. Now,
we look at the results for the knn search.

[source,console-result]
----
"hits" : [
    {
        "_index" : "rrf-index",
        "_id" : "3",                   <1>
        "_score" : 1.0,
        "_source" : {
            "rrf_integer" : 1,
            "rrf_vector" : [3],
            "rrf_text" : "rrf rrf rrf"
        }
    },
    {
        "_index" : "rrf-index",
        "_id" : "2",                   <2>
        "_score" : 0.5,
        "_source" : {
            "rrf_integer" : 2,
            "rrf_vector" : [4],
            "rrf_text" : "rrf rrf"
        }
    },
    {
        "_index" : "rrf-index",
        "_id" : "1",                   <3>
        "_score" : 0.2,
        "_source" : {
            "rrf_integer" : 1,
            "rrf_vector" : [5],
            "rrf_text" : "rrf"
        }
    },
    {
        "_index" : "rrf-index",
        "_id" : "5",                   <4>
        "_score" : 0.2,
        "_source" : {
            "rrf_integer" : 1,
            "rrf_vector" : [1]
        }
    }
]
----
// TEST[skip:example fragment]
<1> rank 1, `_id` 3
<2> rank 2, `_id` 2
<3> rank 3, `_id` 1 (tiebreaker where `1` is less than `5` for `_id`)
<4> rank 4, `_id` 5

We can now take the two individually ranked result sets and apply the
RRF formula to them to get our final ranking.

[source,python]
----
# doc  | query     | knn       | score
_id: 1 = 1.0/(1+4) + 1.0/(1+3) = 0.4500
_id: 2 = 1.0/(1+3) + 1.0/(1+2) = 0.5833
_id: 3 = 1.0/(1+2) + 1.0/(1+1) = 0.8333
_id: 4 = 1.0/(1+1)             = 0.5000
_id: 5 =             1.0/(1+4) = 0.2000
----
// NOTCONSOLE

We rank the documents based on the RRF formula with a `window_size` of `5`
truncating the bottom `2` docs in our RRF result set with a `size` of `3`.
We end with `_id: 3` as `_rank: 1`, `_id: 2` as `_rank: 2`, and
`_id: 4` as `_rank: 3`. This ranking matches the result set from the
original RRF search as expected.
