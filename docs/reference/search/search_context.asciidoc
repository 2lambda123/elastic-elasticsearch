[[search-context]]
==== Search Context

By default, a search request executes against the latest point in time readers of the
target indices. Sometimes it's preferred to execute multiple search requests using
the same point in time readers. For example, the combined result of the initial and
subsequent search_after requests is more consistent if they use the same point in time
readers. This can be done by using a single search context for all search requests.

A search context must be opened in a separate step before being used in subsequent
search requests. The keep_alive parameter tells Elasticsearch how long it should keep
the seach context alive, e.g. `?keep_alive=5m`.

[source,console]
--------------------------------------------------
POST /twitter/_search_context?keep_alive=1m
--------------------------------------------------
// TEST[setup:twitter]

The result from the above request includes a `id`, which should
be passed to the `id` of the `search_context` parameter of a search request.

POST /_search <1>
{
    "size": 100,
    "query": {
        "match" : {
            "title" : "elasticsearch"
        }
    },
    "search_context": {
	    "id":  "46ToAwEHdHdpdHRlchZSa1dRZDFELVNLbTZkQVJudUtGMFFnAAAWNVAwS09JWTdTRUdibWE1ZC1id0tjQRRURnhPWjNFQmI3bmVOeVZReS1tRAAAAAAAAAAB", <2>
	    "keep_alive": "1m"  <3>
    }
}

<1> A search request with `search_context` must not specify `index`, `routing`,
and `preferences` as these parameters are copied from the `search_context`.
<2> The `id` parameter tells Elasticsearch to execute the request using
the point-in-time readers from this search context id.
<3> The `keep_alive` parameter tells Elasticsearch how long it should extend
the time to live of the search context

IMPORTANT: The open search context request and each subsequent search request can
return different `id`; thus always use the most recently received `id` for the
next search request.

[[search-context-keep-alive]]
===== Keeping the search context alive
The `keep_alive` parameter, which is passed to a open search context request and
search request, extends the time to live of the search context. The value
(e.g. `1m`, see <<time-units>>) does not need to be long enough to
process all data -- it just needs to be long enough for the next request.

Normally, the background merge process optimizes the index by merging together
smaller segments to create new, bigger segments. Once the smaller segments are
no longer needed they are deleted. However, open search contexts prevents the
old segments from being deleted since they are still in use.

TIP: Keeping older segments alive means that more disk space and file handles
are needed. Ensure that you have configured your nodes to have ample free file
handles. See <<file-descriptors>>.

Additionally, if a segment contains deleted or updated documents then the search
context must keep track of whether each document in the segment was live at the
time of the initial search request. Ensure that your nodes have sufficient heap
space if you have many open search contexts on an index that is subject to ongoing
deletes or updates.

You can check how many search contexts are open with the
<<cluster-nodes-stats,nodes stats API>>:

[source,console]
---------------------------------------
GET /_nodes/stats/indices/search
---------------------------------------

===== Close search context API

Search contexts are automatically closed when the `keep_alive` has
been elapsed. However keeping search contexts as a cost, as discussed in the
<<search-context-keep-alive,previous section>> so search context should be
explicitly closed as soon as they are no longer used in search requests.

[source,console]
---------------------------------------
DELETE /_search_context
{
    "id" : "46ToAwEHdHdpdHRlchZSa1dRZDFELVNLbTZkQVJudUtGMFFnAAAWNVAwS09JWTdTRUdibWE1ZC1id0tjQRRURnhPWjNFQmI3bmVOeVZReS1tRAAAAAAAAAAB"
}
---------------------------------------
// TEST[catch:missing]
