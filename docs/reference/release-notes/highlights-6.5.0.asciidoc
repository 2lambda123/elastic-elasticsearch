[[release-highlights-6.5.0]]
== 6.5.0 release highlights
++++
<titleabbrev>6.5.0</titleabbrev>
++++

coming[6.5.0]

See also <<release-notes-6.5.0,{es} 6.5.0 release notes>>. 

[float]
=== Audit security events in new structured logs 

By default, when you enable auditing, it uses the 
{stack-ov}/audit-log-output.html[logfile audit output], which persists events to 
a `<clustername>_audit.log` file in the logs directory. This file is new to 
version 6.5 and prints audit entries as JSON documents. 

For backwards compatibility purposes, a `<clustername>_access.log` with the old style of 
formatting is also generated. See also <<breaking_65_settings_changes>>. 

[float]
=== Discover the structure of text files

experimental[] The new <<ml-find-file-structure,find file structure API>> 
determines the structure of a text file. It also returns statistics about the 
most common values of the detected fields and mappings that you can use when you 
ingest the file into {es}. If you want to influence the output, you can specify 
optional parameters. For example, if the file contains semi-structured text, you 
can specify a Grok pattern or let the tool generate it. This API is also used by 
the new File Data Visualizer in {kib}.  

[float]
=== Improved {ml} results for partitioned multi-metric jobs

If you use the +partition_field_name+ or +by_field_name+ parameters in a {ml} job (or the 
*Split Data* field in the {kib} multi-metric job wizard), it generates many 
simultaneous analyses that are modeled independently. In 6.5, we have decreased 
the influence of the anomaly scores in each partition on other partitions' scores. 
The overall effect of the change is to produce a much wider range of scores in 
partitioned multi-metric jobs.

[float]
=== Find multi-bucket anomalies in {ml} jobs

Sometimes events are not interesting or anomalous in the context of a single 
bucket. However, they become interesting when you take into consideration a 
sequence of buckets as a whole. In 6.5, there is a new {ml} 
_multi-bucket analysis_, which uses features from multiple contiguous buckets 
for anomaly detection. The final anomaly score is now a combination of values 
from both the “standard” single-bucket analysis and the new multi-bucket 
analysis. A new `multi_bucket_impact` property in the 
<<ml-results-records,record results>> indicates how strongly either form of 
analysis influences the score. In {kib}, anomalies with medium or high 
multi-bucket impact are depicted in the *Anomaly Explorer* and the 
*Single Metric Viewer* with a cross symbol instead of a dot. 
