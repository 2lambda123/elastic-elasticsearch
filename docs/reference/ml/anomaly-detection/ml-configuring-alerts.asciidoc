[role="xpack"]
[[ml-configuring-alerts]]
= Configuring {anomaly-detect} alerts

{anomaly-detect-cap} alerts run scheduled checks on an {anomaly-job} or a group 
of jobs to detect anomalies with certain conditions. If an {anomaly} meets the 
conditions, the alert triggers the defined action. For example, you can create 
an alert that checks an {anomaly-job} in every fifteen minutes for critical 
anomalies and notify you in an email. This page helps you to configure an 
{anomaly-detect} alert. To learn more about alerts in the {stack}, refer to 
{kibana-ref}/alerting-getting-started.html#alerting-getting-started[Alerting and Actions].


[[creating-anomaly-alerts]]
== Creating an alert

{anomaly-detect-cap} alerts can be created in the {anomaly-job} wizard or under 
**Stack management > Alerts and Actions**. On the *Create alert* template, 
select *{anomaly-detect-cap} alert* under the {ml-cap} section, then give a name 
to the alert and optionally provide tags.

// SCREENSHOT

Specify the time interval for the alert to check detected anomalies. It is 
recommended to select an interval that is similar to the bucket span of the 
associated job. You can also select a notification method by using the _Notify_ 
selector. There are three notification options:

* Notify only on status change: actions are triggered when the alert status 
  changes.
* Notify every time alert is active: actions are triggered every time when the 
  alert checks changes.
* Notify on a custom action interval: actions run by using an interval that you 
  configured.
  
Select the {anomaly-job} or the group of {anomaly-jobs} that is checked by the 
alert. In case you select a group, the {anomaly-detect} alert handles possible 
duplications in the results, hence they don't trigger the configured actions 
unnecessarily. If you assign additional jobs to the group, the alert 
automatically check the new jobs the next time when it runs.

You can select the result type of the {anomaly-job} that the alert checks. 
{anomaly-detect-cap} produces three types of results: bucket, record, and 
influencer. Bucket result type is selected by default.

// SCREENSHOT

For each alert, you can configure which severity level triggers it. The severity 
threshold is based on the `anomaly_score` which indicates the significance of a 
given anomaly compared to previous anomalies. The default severity level is 
critical (anomalies with an `anomaly_score` 75 or higher).

You can also test the configured conditions and check the sample results by 
providing a valid interval in the respective field.


[[defining-actions]]
== Defining actions

As a next step, connect your alert to actions that use supported built-in 
integrations. Actions are {kib} services or third-party integrations that run 
when the alert conditions are met.

// SCREENSHOT

For example, you can choose _Slack_ as an action type and configure it to send a 
message to a channel you selected or you can also create an index connector that 
writes the JSON object you configure to a specific index. It's also possible to 
customize the notification messages. A list of variables is available to include 
in the message, like job ID, anomaly score, time, or top influencers.

// SCREENSHOT