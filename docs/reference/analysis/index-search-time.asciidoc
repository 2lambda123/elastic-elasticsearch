[[analysis-index-search-time]]
=== Index and search analysis

Text analysis occurs at two times:

Index time::
When a document is indexed, any <<text,`text`>> field values are analyzed.

Search time::
When running a <<full-text-queries,full-text search>> on a `text` field,
the query string (the text the user is searching for) is analyzed.
+
Search time is also called _query time_.

The analyzer, or set of analysis rules, used at each time is called the _index
analyzer_ or _search analyzer_ respectively.

[[analysis-same-index-search-analyzer]]
==== How the index and search analyzer work together

In most cases, the same analyzer should be used at index and search time.

This converts the text in the query string into the same form of tokens as those
indexed in the field. In turn, this ensures the tokens match as expected during
a search.

.**Example**
[%collapsible]
====

A document is indexed with the following value in a `text` field:

[source,text]
------
"The QUICK brown foxes jumped over the dog!"
------

The index analyzer for the field converts the value into tokens. It then applies
several changes to normalize the tokens. In the end, the following tokens
are indexed as the field value:

[source,text]
------
[ quick, brown, fox, jump, over, dog ]
------

Later, a user searches the same `text` field for:

[source,text]
------
"Quick fox"
------

The user expects this search to return any document containing `quick`, `fox`,
or other relevant words. The search results should include the document
containing `"The QUICK brown foxes jumped over the dog!"`.

However, the provided query string does not contain the exact words contained
in the document's original text:

* `quick` vs `QUICK`
* `fox` vs `foxes`

To account for this, the query string is analyzed using the same analyzer from
index time. The analyzer produces the following tokens for the query string:

[source,text]
------
[ quick, fox ]
------

{es} can compare these query string tokens to the ones indexed in the `text`
field.

[options="header"]
|===
|Token     | Query string | `text` field
|`quick`   | X            | X
|`brown`   |              | X
|`fox`     | X            | X
|`jump`    |              | X
|`over`    |              | X
|`dog`     |              | X
|===

`quick` and `fox` tokens are exact matches. This means the search returns the
document containing `"The QUICK brown foxes jumped over the dog!"`, just as the
user expects.
====

[[different-analyzers]]
==== When to use a different search analyzer

While less common, it sometimes makes sense to use different analyzers at index
and search time. To enable this, {es} allows you to
<<specify-search-analyzer,specify a separate search analyzer>>.

Generally, a separate search analyzer should only be specified when using the
same form of tokens for field values and query strings would create unexpected
or irrelevant search matches.

[[different-analyzer-ex]]
.*Example*
[%collapsible]
====
{es} is used to create a search engine that matches only words that start with
a provided prefix. For instance, a search for `tr` should return `tram` or
`trope`â€”but never `taxi` or `bat`.

A document is indexed. This document contains one such word in a `text` field:

[source,text]
------
"Apple"
------

The index analyzer for the field converts the value into tokens and normalizes
them. In this case, each of the final tokens represents a potential prefix for
the word:

[source,text]
------
[ a, ap, app, appl, apple]
------

The tokens are then indexed.

Later, a user searches the same `text` field for:

[source,text]
------
"appli"
------

The user expects this search to match only words that start with `appli`,
such as `appliance` or `application`. The search should not match `apple`.

However, if the same analyzer is used on this query string, it would produce the
following tokens:

[source,text]
------
[ a, ap, app, appl, appli ]
------

When these query string tokens are compared to the ones indexed for `apple`,
several match.

[options="header"]
|===
|Token      | `appli`      | `apple`
|`a`        | X            | X
|`ap`       | X            | X
|`app`      | X            | X
|`appl`     | X            | X
|`appli`    |              | X
|===

This means the search would erroneously match `apple`. Not only that, it would
match any such word starting with `a`. That's a lot of irrelevant matches.

To fix this, you can specify a different search analyzer for the `text` field.
This means different analysis changes would be applied to the query string when
searching the field.

In this case, you could specify a search analyzer that produces a single token
rather than a set of prefixes:

[source,text]
------
[ appli ]
------

This query string token would only match tokens words that start with `appli`,
which better aligns with the user's search expectations.
====
