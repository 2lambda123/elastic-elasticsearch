
== Text analysis overview
++++
<titleabbrev>Overview</titleabbrev>
++++

Text analysis enables {es} to perform full-text search, where the search returns
all _relevant_ results rather than just exact matches.

For example, a full-text search for `Quick fox jumps` should not only return
documents containing that exact search string but also documents containing
similar or related words, like  `fast fox` or even `foxes leap`.

[discrete]
[[tokenization]]
=== Tokenization

Analysis makes full-text search possible by breaking an text down into smaller
chunks, called _tokens_. In most cases, these tokens are individual words.

For example, without analysis, the text `Quick brown fox` can only be
matched by searches for the exact string `Quick brown fox`. With analysis,
the text is converted to the tokens `[Quick, brown, fox]`, which can
be matched by searches for `Quick fox`, `fox brown`, or other variations.

While improved, this example search experience still has a few problems:

*  A search for `Quick` would not match `quick`, even though you likely want
either term to match the other

* `fox` and `foxes` share the same root word. However,
a search for `foxes` would not match `fox` or vice versa.

* While `jumps` and `leaps` don't share a root word, they are synonyms and have
a similar meaning. However, a search for one would not match the other.

[discrete]
[[normalization]]
=== Normalization

To solve these problems, text analysis can _normalize_ these tokens into a
standard format. This allows you to match tokens that are not exactly the same
as the search terms, but similar enough to still be relevant. For example:

* `Quick` can be lowercased: `quick`.

* `foxes` can be _stemmed_, or reduced to its root word: `fox`.

* `jump` and `leap` are synonyms and can be indexed as a single word: `jump`.

To ensure search terms match these words as intended, you can apply the same
tokenization and normalization rules to the query string. For example, a search
for `Foxes leap` can be normalized to a search for `fox jump`.

[discrete]
[[analysis-customization]]
=== Customize text analysis

Text analysis is performed by an <<analyzer-anatomy,_analyzer_>>, a set of rules
that govern the entire process.

{es} includes a default analyzer, called the
<<analysis-standard-analyzer,standard analyzer>>, which works well for most use
cases right out of the box.

If you want to further tailor your search experience, you can choose a different
<<analysis-analyzers,built-in analyzer>> or even
<<analysis-custom-analyzer,configure a custom one>>. A custom analyzer gives you
control over each step of the analysis process, including:

* Changes to the text _before_ tokenization

* How text is converted to tokens

* Normalization changes made to tokens before indexing or search