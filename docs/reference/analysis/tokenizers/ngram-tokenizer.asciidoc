[[analysis-ngram-tokenizer]]
=== Ngram Tokenizer

A tokenizer of type `ngram`.

The following are settings that can be set for a `ngram` tokenizer type:

[cols="<,<,<",options="header",]
|=======================================================================
|Setting |Description |Default value
|`min_gram` |Minimum size of a single n-gram, in codepoints. Defaults to `1`.
|`max_gram` |Maximum size of a single n-gram, in codepoints . Defaults to `2`.
|`token_chars` | The types of characters to keep in the
tokens. The `edgeNgram` tokenizer splits on characters that don't belong to any
of these classes. Specified as an array of character classes. The supported
character classes are: `letter` (for example `a`, `b`, `ï` or `京`), 
`digit` (for example,  `3` or `7`),
`whitespace`  (for example `" "` or `"\n"`), 
`punctuation` (for example `!` or `"`), 
`symbol`     (for example `$` or `√`).
 Defaults to `[]` (Keep all characters).
|=======================================================================


[float]
==== Example

[source,js]
--------------------------------------------------
    curl -XPUT 'localhost:9200/test' -d '
    {
        "settings" : {
            "analysis" : {
                "analyzer" : {
                    "my_ngram_analyzer" : {
                        "tokenizer" : "my_ngram_tokenizer"
                    }
                },
                "tokenizer" : {
                    "my_ngram_tokenizer" : {
                        "type" : "nGram",
                        "min_gram" : "2",
                        "max_gram" : "3",
                        "token_chars": [ "letter", "digit" ]
                    }
                }
            }
        }
    }'

    curl 'localhost:9200/test/_analyze?pretty=1&analyzer=my_ngram_analyzer' -d 'FC Schalke 04'
    # FC, Sc, Sch, ch, cha, ha, hal, al, alk, lk, lke, ke, 04
--------------------------------------------------
