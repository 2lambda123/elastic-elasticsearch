[[analysis-keyword-repeat-tokenfilter]]
=== Keyword repeat token filter
++++
<titleabbrev>Keyword repeat</titleabbrev>
++++

Outputs each token in a stream twice:

* Once as a <<stemmer-keyword,keyword>>, which is excluded from
  <<stemming,stemming>>
* Once as a non-keyword, which can be stemmed normally

This allows you to preserve both a stemmed and unstemmed version of each token.

The `keyword_repeat` filter uses Lucene's
https://lucene.apache.org/core/{lucene_version_path}/analyzers-common/org/apache/lucene/analysis/miscellaneous/KeywordRepeatFilter.html[KeywordRepeatFilter].

[TIP]
====
If you only want to exclude specific tokens from stemming, we recommend using
the <<analysis-keyword-marker-tokenfilter,`keyword_marker`>> token filter. 
====

[[analysis-keyword-repeat-tokenfilter-analyze-ex]]
==== Example

The following <<indices-analyze,analyze API>> request uses the `keyword_repeat`
filter to produce both stemmed and unstemmed versions of 
`quick foxes jumping`:


[source,console]
--------------------------------------------------
GET _analyze
{
  "tokenizer": "standard",
  "filter": [
    "keyword_repeat",
    {
      "type": "stemmer",
      "name": "english"
    }
  ],
  "text": "quick foxes jumping"
}
--------------------------------------------------

The filter produces the following tokens:

[source,text]
--------------------------------------------------
[ quick, quick, foxes, fox, jumping, jump ]
--------------------------------------------------

Note that the `quick` token was not stemmed, which created duplicate tokens. You
can remove these duplicate tokens using the
<<analysis-remove-duplicates-tokenfilter,`remove_duplicates`>> filter. See
<<analysis-keyword-repeat-tokenfilter-analyzer-ex>>.

/////////////////////
[source,console-result]
--------------------------------------------------
{
  "tokens": [
    {
      "token": "quick",
      "start_offset": 0,
      "end_offset": 5,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "quick",
      "start_offset": 0,
      "end_offset": 5,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "foxes",
      "start_offset": 6,
      "end_offset": 11,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "fox",
      "start_offset": 6,
      "end_offset": 11,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "jumping",
      "start_offset": 12,
      "end_offset": 19,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "jump",
      "start_offset": 12,
      "end_offset": 19,
      "type": "<ALPHANUM>",
      "position": 2
    }
  ]
}
--------------------------------------------------
/////////////////////


[[analysis-keyword-repeat-tokenfilter-analyzer-ex]]
==== Add to an analyzer

[IMPORTANT]
====
To work, the `keyword_repeat` filter must be placed _before_ any
<<stemming-token-filters,stemming filters>>, such as the
<<analysis-stemmer-tokenfilter,`stemmer`>> or
<<analysis-porterstem-tokenfilter,`porter_stem`>> token filter, in the
<<analysis-custom-analyzer,analyzer configuration>>.

The `keyword_repeat` filter can produce duplicate tokens, even after stemming.
To remove these duplicates, add a
<<analysis-remove-duplicates-tokenfilter,`remove_duplicates`>> token filter
_after_ any stemming filters in the analyzer configuration.
====

The following <<indices-create-index,create index API>> request uses the
`keyword_repeat` token filter and other filters to configure a new
<<analysis-custom-analyzer,custom analyzer>>. Note the order of the filters
included in the analyzer. Based on this order, the analyzer preserves both
stemmed and unstemmed versions of tokens as follows:

. The `keyword_repeat` filter creates two versions of each token: a keyword,
which is excluded from stemming, and a non-keyword, which can be stemmed.

. The `porter_stem` filter stems the non-keyword tokens, if applicable. The
keyword tokens are left unchanged.

. The `remove_duplicates` filter removes any duplicate tokens.

[source,console]
--------------------------------------------------
PUT keyword_repeat_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stemmed_and_unstemmed": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "keyword_repeat",
            "porter_stem",
            "remove_duplicates"
          ]
        }
      }
    }
  }
}
--------------------------------------------------
