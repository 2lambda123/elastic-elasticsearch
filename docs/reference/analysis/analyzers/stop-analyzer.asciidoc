[[analysis-stop-analyzer]]
=== Stop Analyzer

The `stop` analyzer wraps the <<analysis-lowercase-tokenizer, 
`lowercase`>> tokenizer and the <<analysis-stop-tokenfilter,`stop`  
>> token filter. The `lowercase` tokenizer splits tokens on 
non-letter boundaries and converts them to lowercase. The `stop`
token filter removes tokens that match any of the specified
stopwords. 

You can configure the following settings for a `stop` analyzer:

[cols="<,<",options="header",]
|=======================================================================
|Setting |Description
|`stopwords` |A list of stopwords or the name of a predefined list. 
Defaults to the predefined `_english_` list. 
Use `stopwords: _none_` to explicitly specify an empty stopword list.
See <<analysis-stop-tokenfilter>>
for the available predefined lists.
|`stopwords_path` |A path to a file that contains a list of stopwords. 
Can be relative to the `config` location or an absolute path.
|=======================================================================

For example, using the `stop` analyzer to process the string 
"Let the wild rumpus start! (bit.ly/1wsCiKv)" with the default stop words generates
the following tokens:

 `let, wild, rumpus, start, bit, ly, wscikv`

[source,js]
------------------------------------------------------------
include::../../snippets/analysis/stop-analyzer.json[]
------------------------------------------------------------
// SENSE: analysis/stop-analyzer.json

The following example configures custom stopwords for a `stop` analyzer 
from a file.

[source,js]
--------------------------------------------------
include::../../snippets/analysis/configure-stop-analyzer.json[]
--------------------------------------------------
// SENSE: analysis/configure-stop-analyzer.json