[chapter]
[[getting-started]]
= Quick start

This guide helps beginners learn how to:

* Install and run {es} in a test environment
* Add data to {es}
* Search and sort data
* Extract fields from unstructured content during a search

We do not recommend using this guide to set up a self-managed production
deployment. To install and configure {es} in production, see
<<install-elasticsearch>> and <<settings>>.

[discrete]
[[run-elasticsearch]]
=== Step 1. Run {es}

The best way to run {es} is our hosted {ess} on {ecloud}. If needed, you can
also run and self-manage {es} on your own infrastructure.

include::{es-repo-dir}/tab-widgets/code.asciidoc[]
include::{es-repo-dir}/tab-widgets/quick-start-install-widget.asciidoc[]

[discrete]
[[make-api-call]]
=== Step 2. Make an API call

You send data and other requests to {es} using REST APIs. This lets you interact
with {es} using any client that sends HTTP requests, such as
https://curl.se[curl]. You can also use {kib}'s console to make API calls.

include::{es-repo-dir}/tab-widgets/api-call-widget.asciidoc[]

[discrete]
[[add-data]]
=== Step 3. Add data

You add data to {es} as JSON objects called documents. {es} stores these
documents in searchable indices. For time series data, you typically add data
to <<data-streams,data streams>> made up of multiple auto-generated indices.

The following <<docs-index_,index API>> request adds a JSON document containing
a `@timestamp` and a log message, `event.original`, to a test data stream named
`logs-my_app-default`. Since `logs-my_app-default` doesn't exist, the request
automatically creates it.

A data stream requires a matching <<create-index-template,index template>>. This
stream uses a built-in template for the `logs-*-*` pattern. Data streams also
require documents contain a `@timestamp` field.

[source,console]
----
POST logs-my_app-default/_doc
{
  "@timestamp": "2099-05-06T16:21:15.000Z",
  "event": {
    "original": "192.0.2.42 - - [06/May/2099:16:21:15 +0000] \"GET /images/bg.jpg HTTP/1.0\" 200 24736"
  }
}
----
// TEST[s/_doc/_doc?refresh=wait_for/]

The response includes metadata that {es} generates for the document:

* The `_index` of the data stream that stores the document. For data streams,
  the index name is automatically generated.
* An `_id` that is unique to the document within an index.

[source,console-result]
----
{
  "_index": ".ds-logs-my_app-default-2099-05-06-000001",
  "_id": "gl5MJXMBMk1dGnErnBW8",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 0,
  "_primary_term": 1
}
----
// TESTRESPONSE[s/"_index": ".ds-logs-my_app-default-2099-05-06-000001"/"_index": $body._index/]
// TESTRESPONSE[s/"_id": "gl5MJXMBMk1dGnErnBW8"/"_id": $body._id/]

[discrete]
[[add-bulk-data]]
=== Step 4. Add bulk data

To add a large number of documents in one request, use the <<docs-bulk,bulk
API>>. Bulk data must be newline-delimited JSON (NDJSON). Each line must end in
a newline character (`\n`), including the last line.

[source,console]
----
PUT logs-my_app-default/_bulk
{ "create": { } }
{ "@timestamp": "2099-05-06T16:24:32.000Z", "event": { "original": "192.0.2.242 - - [06/May/2020:16:24:32 -0500] \"GET /images/hm_nbg.jpg HTTP/1.0\" 304 0" } }
{ "create": { } }
{ "@timestamp": "2099-05-06T16:25:42.000Z", "event": { "original": "192.0.2.255 - - [06/May/2099:16:25:42 +0000] \"GET /favicon.ico HTTP/1.0\" 200 3638" } }
----
// TEST[continued]
// TEST[s/_bulk/_bulk?refresh=wait_for/]

[discrete]
[[qs-search-data]]
=== Step 5. Search data

Indexed documents are available for search in near real-time. Use the
<<search-search,search API>> to search your indexed data.

The following search matches all data in `logs-my_app-default` and sorts results
by `@timestamp` in descending order.

[source,console]
----
GET logs-my_app-default/_search
{
  "query": {
    "match_all": { }
  },
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]

By default, the `hits` section of the response includes up to the first 10
documents that match the search. Each hit contains a `_source`, the original
JSON object submitted during indexing.

[source,console-result]
----
{
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 3,
      "relation": "eq"
    },
    "max_score": null,
    "hits": [
      {
        "_index": ".ds-logs-my_app-default-2099-05-06-000001",
        "_id": "PdjWongB9KPnaVm2IyaL",
        "_score": null,
        "_source": {
          "@timestamp": "2099-05-06T16:25:42.000Z",
          "event": {
            "original": "192.0.2.255 - - [06/May/2099:16:25:42 +0000] \"GET /favicon.ico HTTP/1.0\" 200 3638"
          }
        },
        "sort": [
          4081767942000
        ]
      },
      ...
    ]
  }
}
----
// TESTRESPONSE[s/"took": 2/"took": $body.took/]
// TESTRESPONSE[s/"_index": ".ds-logs-my_app-default-2099-05-06-000001"/"_index": $body.hits.hits.0._index/]
// TESTRESPONSE[s/"_id": "PdjWongB9KPnaVm2IyaL"/"_id": $body.hits.hits.0._id/]
// TESTRESPONSE[s/\.\.\./$body.hits.hits.1,$body.hits.hits.2/]

[discrete]
[[get-specific-fields]]
=== Step 6. Get specific fields

Parsing the entire `_source` can be unwieldy for large documents. To exclude it
from the response, set the `_source` parameter to `false`. Instead, use the
`fields` parameter to retrieve only the fields you want.

[source,console]
----
GET logs-my_app-default/_search
{
  "query": {
    "match_all": { }
  },
  "fields": [
    "@timestamp"
  ],
  "_source": false,
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]

The response contains each hit's `fields` values as a flat array.

[source,console-result]
----
{
  "took": 8,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 3,
      "relation": "eq"
    },
    "max_score": null,
    "hits": [
      {
        "_index": ".ds-logs-my_app-default-2099-05-06-000001",
        "_id": "PdjWongB9KPnaVm2IyaL",
        "_score": null,
        "fields": {
          "@timestamp": [
            "2099-05-06T16:25:42.000Z"
          ]
        },
        "sort": [
          4081767942000
        ]
      },
      ...
    ]
  }
}
----
// TESTRESPONSE[s/"took": 8/"took": $body.took/]
// TESTRESPONSE[s/"_index": ".ds-logs-my_app-default-2099-05-06-000001"/"_index": $body.hits.hits.0._index/]
// TESTRESPONSE[s/"_id": "PdjWongB9KPnaVm2IyaL"/"_id": $body.hits.hits.0._id/]
// TESTRESPONSE[s/\.\.\./$body.hits.hits.1,$body.hits.hits.2/]

[discrete]
[[search-date-range]]
=== Step 7. Search a date range

The `query` parameter supports several <<query-dsl,Query DSL>> query types. To
search across a specific time or IP range, use a
<<query-dsl-range-query,`range`>> query.

[source,console]
----
GET logs-my_app-default/_search
{
  "query": {
    "range": {
      "@timestamp": {
        "gte": "2099-05-05",
        "lt": "2099-05-07"
      }
    }
  },
  "fields": [
    "@timestamp"
  ],
  "_source": false,
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]

Use <<date-math,date math>> to define relative time ranges. The following
search will not any documents in `logs-my_app-default`.

[source,console]
----
GET logs-my_app-default/_search
{
  "query": {
    "range": {
      "@timestamp": {
        "gte": "now-1d/d",
        "lt": "now/d"
      }
    }
  },
  "fields": [
    "@timestamp"
  ],
  "_source": false,
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]

[discrete]
[[extract-fields]]
=== Step 8. Extract fields from unstructured content

Use a <<runtime-search-request,runtime field>> containing a
<<modules-scripting-painless,Painless script>> and <<grok-basics,grok patterns>>
to extract fields from unstructured content, such as log messages. Include the
extracted field names in the `fields` parameter.

The following search uses the `runtime_mappings` parameter to extract the
`source.ip` address from the `event.original` field.

[source,console]
----
GET logs-my_app-default/_search
{
  "runtime_mappings": {
    "source.ip": {
      "type": "ip",
      "script": """
        String sourceip=grok('%{IPORHOST:sourceip} .*').extract(doc[ "event.original" ].value)?.sourceip;
        if (sourceip != null) emit(sourceip);
      """
    }
  },
  "query": {
    "range": {
      "@timestamp": {
        "gte": "2099-05-05",
        "lt": "2099-05-07"
      }
    }
  },
  "fields": [
    "@timestamp",
    "source.ip"
  ],
  "_source": false,
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]

[discrete]
[[combine-queries-sorts]]
=== Step 9. Combine queries and sorts

To combine multiple queries, use the <<query-dsl-bool-query,`bool` query>>. The
following search uses a `bool` query to combine multiple queries, including a
`range` query on the `source.ip` runtime field. The search also sorts results by
`source.ip`.

[source,console]
----
GET logs-my_app-default/_search
{
  "runtime_mappings": {
    "source.ip": {
      "type": "ip",
      "script": """
        String sourceip=grok('%{IPORHOST:sourceip} .*').extract(doc[ "event.original" ].value)?.sourceip;
        if (sourceip != null) emit(sourceip);
      """
    }
  },
  "query": {
    "bool": {
      "filter": [
        {
          "range": {
            "@timestamp": {
              "gte": "2099-05-05",
              "lt": "2099-05-07"
            }
          }
        },
        {
          "range": {
            "source.ip": {
              "gte": "192.0.2.0",
              "lte": "192.0.2.255"
            }
          }
        }
      ]
    }
  },
  "fields": [
    "@timestamp",
    "source.ip"
  ],
  "_source": false,
  "sort": [
    {
      "@timestamp": "desc",
      "source.ip": "desc"
    }
  ]
}
----
// TEST[continued]

[discrete]
[[clean-up]]
=== Step 10. Delete data

Index more data to your data stream and explore the search options in outlined
in <<search-your-data>>. When you're done, use the
<<indices-delete-data-stream,delete data stream API>> to delete your test data
stream and it backing indices.

[source,console]
----
DELETE _data_stream/logs-my_app-default
----
// TEST[continued]

[discrete]
[[stop-remove-docker-containers]]
=== Step 11. Stop and remove your Docker containers

TIP: If you're using {ess}, skip this step.

If you're using Docker to run {es} or {kib}, run the following command in a new
terminal session to stop the containers:

[source,sh]
----
docker stop es01-test
docker stop kib01-test
----

To remove the containers, run:

[source,sh]
----
docker rm es01-test
docker rm kib01-test
----

[discrete]
[[whats-next]]
=== What's next?

* To install and configure {es} in production, see <<install-elasticsearch>> and
<<settings>>. To secure {es} and the {stack}, see <<secure-cluster>>.

* Get the most out of your time series data by setting up data tiers and
{ilm-init}. See <<use-elasticsearch-for-time-series-data>>.

* Use {fleet} and {agent} to collect logs and metrics directly from your data
sources and send them to {es}. See the
{fleet-guide}/fleet-quick-start.html[{fleet} Quick Start].

* Use {kib} to explore, visualize, and manage your {es} data. See the
{kibana-ref}/get-started.html[{kib} Quick Start].
