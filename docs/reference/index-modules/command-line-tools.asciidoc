[[index-modules-command-line-tools]]

== Command-line tools

In some cases (a bad drive, user error) the translog or Lucene index on a shard copy
can become corrupted. When this corruption is detected by Elasticsearch due to mismatching
checksums, Elasticsearch will fail that shard copy and refuse to use that copy
of the data.

*Note*: If there are other copies of the shard available then
Elasticsearch will automatically recover from one of them using the normal
shard allocation and recovery mechanism.  In particular, if the corrupt shard
copy was the primary when the corruption was detected then one of its replicas
will be promoted in its place.

You can also use <<modules-snapshots,snapshot and restore>> to restore the index.

Please consider using of this tool like the last resort if there is no copy of the data
from which Elasticsearch can recover successfully.

We provide a command-line tool for this - `elasticsearch-shard`.

The cost of applying this tool is losing the corrupted data. It could be any lost data
regardless of time: could be a recent or an old data.

[WARNING]
The `elasticsearch-shard` tool should *not* be run while Elasticsearch is
running. If you attempt to run this tool while Elasticsearch is running, you
will permanently lose the documents that were contained only in the translog!

[WARNING]
After dropping the corrupted part the allocation id of the shard is changed.
`elasticsearch-shard` provides details of command that has to be run after the node
restart to apply changes:
You should run follow command to apply allocation id changes:
[source,txt]
--------------------------------------------------
$ curl -XPOST 'http://localhost:9200/_cluster/reroute' -d '
{
  "commands" : [
    {
      "allocate_stale_primary" : {
        "index" : "twitter",
        "shard" : 0,
        "node" : "pAfJBgAAQACIfI2M_____w",
        "accept_data_loss" : true
      }
    }
  ]
}'
--------------------------------------------------

=== What to do if the translog becomes corrupted?

In order to drop corrupted translog use `truncate-translog` subcommand:

* you should specify index name with `--index` and shard id `--shard-id`
* or specify the full path to corrupted translog with the `-d` option

[source,txt]
--------------------------------------------------
$ bin/elasticsearch-shard truncate-translog -d /var/lib/elasticsearchdata/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/
Checking existing translog files
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!   WARNING: Elasticsearch MUST be stopped before running this tool   !
!                                                                     !
!   WARNING:    Documents inside of translog files will be lost       !
!                                                                     !
!   WARNING:          The following files will be DELETED!            !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
--> data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-41.ckp
--> data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-6.ckp
--> data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-37.ckp
--> data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-24.ckp
--> data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-11.ckp

Continue and DELETE files? [y/N] y
Reading translog UUID information from Lucene commit from shard at [data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/index]
Translog Generation: 3
Translog UUID      : AxqC4rocTC6e0fwsljAh-Q
Removing existing translog files
Creating new empty checkpoint at [data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog.ckp]
Creating new empty translog at [data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-3.tlog]

Marking index with the new history uuid : TAUddBstTciV9wAiA6sKFA
Changing allocation id ceU7CskxT4yRw4M-GLO1mg to nFa2DcCsSlady4LlnJeaEQ
You should run follow command to apply allocation id changes:

$ curl -XPOST 'http://localhost:9200/_cluster/reroute' -d '
{
  "commands" : [
    {
      "allocate_stale_primary" : {
        "index" : "twitter",
        "shard" : 0,
        "node" : "pAfJBgAAQACIfI2M_____w",
        "accept_data_loss" : true
      }
    }
  ]
}'
Done.
--------------------------------------------------

=== What to do if the Lucene index becomes corrupted?

In a similar cases the index on a shard copy can become corrupted.
Like in case with corrupted translog when index corruption is detected by Elasticsearch due
to mismatching checksums, Elasticsearch will fail that shard copy and refuse to use that copy of the data.
If there are other copies of the shard available then Elasticsearch will automatically recover from one of
them using the normal shard allocation and recovery mechanism.

In order to remove corrupted segments use `remove-corrupted-segments` subcommand:
It writes a new segments file that removes reference to problematic (corrupted) Lucene segments if there is
no copy of the data from which Elasticsearch can recover successfully.

Highly recommended to make a complete backup of your index before using this to remove corrupted documents
from your index!

* you should specify index name with `--index` and shard id `--shard-id`
* or specify the full path to corrupted translog with the `-d` option

You can get an overview of the corruption with `--dry-run` option :

[source,txt]
--------------------------------------------------
$ bin/elasticsearch-shard remove-corrupted-segments --dry-run --index twitter --shard-id 0

Opening index @ /var/lib/elasticsearchdata/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/index/

WARNING: Corrupted segments found - 568 documents are damaged

--------------------------------------------------

Running `remove-corrupted-segments` without `--dry-run` requires interactive confirmation to drop damaged segments:

[source,txt]
--------------------------------------------------

$ bin/elasticsearch-shard remove-corrupted-segments --index twitter --shard-id 0

Opening index @ /var/lib/elasticsearchdata/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/index/

Segments file=segments_8 numSegments=6 version=7.4.0 id=efcaej17mrbjqf9jf5js52e94 userData={history_uuid=3Mu-8x3zTMm8TIZxwTkTZw, local_checkpoint=1896, max_seq_no=1896, max_unsafe_auto_id_timestamp=-1, translog_generation=7, translog_uuid=2n8vuupLQWSh5LDQzRe2fQ}
  1 of 2: name=_0 maxDoc=1
    version=7.4.0
    id=efcaej17mrbjqf9jf5js52e8k
    codec=Lucene70
    compound=true
    numFiles=3
    size (MB)=0.004
    diagnostics = {java.runtime.version=10.0.2+13, java.vendor=Oracle Corporation, java.version=10.0.2, java.vm.version=10.0.2+13, lucene.version=7.4.0, os=Mac OS X, os.arch=x86_64, os.version=10.13.6, source=flush, timestamp=1532081797245}
    no deletions
    test: open reader.........OK [took 0.001 sec]
    test: check integrity.....OK [took 0.000 sec]
    test: check live docs.....OK [took 0.000 sec]
    test: field infos.........OK [9 fields] [took 0.000 sec]
    test: field norms.........OK [2 fields] [took 0.000 sec]
    test: terms, freq, prox...OK [5 terms; 5 terms/docs pairs; 2 tokens] [took 0.000 sec]
    test: stored fields.......OK [2 total field count; avg 2.0 fields per doc] [took 0.000 sec]
    test: term vectors........OK [0 total term vector count; avg 0.0 term/freq vector fields per doc] [took 0.000 sec]
    test: docvalues...........OK [5 docvalues fields; 0 BINARY; 3 NUMERIC; 0 SORTED; 0 SORTED_NUMERIC; 2 SORTED_SET] [took 0.000 sec]
    test: points..............OK [1 fields, 1 points] [took 0.000 sec]

  2 of 2: name=_1 maxDoc=568
    version=7.4.0
    id=efcaej17mrbjqf9jf5js52e8q
    codec=Lucene70
    compound=true
    numFiles=3
    size (MB)=1.148
    diagnostics = {java.runtime.version=10.0.2+13, java.vendor=Oracle Corporation, java.version=10.0.2, java.vm.version=10.0.2+13, lucene.version=7.4.0, os=Mac OS X, os.arch=x86_64, os.version=10.13.6, source=flush, timestamp=1532081798123}
    no deletions
    test: open reader.........FAILED
    WARNING: exorciseIndex() would remove reference to this segment;

WARNING: 1 broken segments (containing 568 documents) detected
Took 0.049 sec total.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!   WARNING:                568 documents will be lost.               !
!                                                                     !
!   WARNING:            YOU WILL LOSE DATA.                           !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

Continue and remove 568 docs from the index ? [y/N]

Writing...
OK
Wrote new segments file "segments_8"

Marking index with the new history uuid : TAUddBstTciV9wAiA6sKFA
Changing allocation id ceU7CskxT4yRw4M-GLO1mg to nFa2DcCsSlady4LlnJeaEQ
You should run follow command to apply allocation id changes:

$ curl -XPOST 'http://localhost:9200/_cluster/reroute' -d '
{
  "commands" : [
    {
      "allocate_stale_primary" : {
        "index" : "twitter",
        "shard" : 0,
        "node" : "pAfJBgAAQACIfI2M_____w",
        "accept_data_loss" : true
      }
    }
  ]
}'
Deleted corrupt marker corrupted_cJv5hCxeTE2p3AucpgCJyg

--------------------------------------------------

You can also use the `-h` option to get a list of all options and parameters
that the `elasticsearch-shard` tool supports.
