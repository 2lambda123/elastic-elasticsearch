[[node-tool]]
== elasticsearch-node
[float]
=== Background

Elasticsearch â‰¤ 6 leniently allows the following unsafe operations:

* Recovery from loss of a majority of master-eligible nodes.

Simply start up enough fresh master-eligible nodes to satisfy
minimum_master_nodes and the cluster will re-form. This is unsafe because there
could have been a cluster-state update that was committed without being accepted
on the surviving nodes.

* Nodes migrating from one cluster to another.

If a node is disconnected from cluster A and then discovers a distinct cluster B
then it will join cluster B. Any indices having shards on the migrating node
will be imported as dangling indices into cluster B, and these shards will be
treated as in-sync even if they were not in-sync in cluster A,
which may confusingly expose an arbitrarily stale shard to searches.

[NOTE]
When we're talking about the loss of nodes, we mean loss of storage for these
nodes. If you still have access to the nodes storage, you should copy
previous nodes data to other nodes and start Elasticsearch.

Starting with Elasticsearch 7 cluster does not really support these operations:

* A cluster that loses a majority of its master-eligible nodes will not
proceed until it finds a majority of precisely those nodes again, using the
persistent node ID for identification. New nodes will have new persistent node
IDs so will not count towards a majority.

* When node tries to join different cluster, cluster UUID comparison will fail.

There is value in supporting these operations for severe disasters,
but this is never done automatically and requires manual user intervention and
acceptance of the risk of data loss.

[float]
=== Strongly prefer restoring from the snapshot
If there is a recent snapshot available, you should use snapshot restore
instead of this tool. Snapshot restore gives you a *consistent* data back
in time. This tool usage gives you *inconsistent* data back in time.


[float]
=== Command line tool
`elasticsearch-node` tool has two modes:

* `elastisearch-node unsafe-bootstap` could be used to bootstrap master-eligible
node in the cluster, where the majority of master eligible nodes is lost, but
 there is at least one master-eligible node available.
* `elastisearch-node detach-cluster` could be used to detach data nodes from
the cluster when the all master eligible nodes are lost in the cluster.

[float]
=== Unsafe bootstrap
If you have lost the majority of master eligible nodes, you can still try to
recover the cluster using `elasticsearch-node unsafe-bootstrap`.

[WARNING]
Execution of this command can lead to arbitrary data loss. Only run this tool
 if you understand what you're doing.

The sequence of bootstrapping your cluster would be the following:

1. Make sure you really lost storage of the majority master eligible nodes in
the cluster.
2. Make sure to stop all *all* master eligible nodes. This
step is *important* to prevent split-brain in the future.
3. From the survived master eligible nodes, pick one.
4. Run `elasticsearch-node unsafe-bootstrap` command as shown below.
5. If you see `Master node was successfully bootstrapped` message, it means
that the tool was able to bootstrap master eligible node.
6. Start bootstrapped master eligible node.
7. Data only nodes should be able to automatically join this node, restart
them if you previously stopped them.
8. Start more master eligible nodes to get desired level of fault-tolerance.

[source, txt]
----
$ ./bin/elasticsearch-node unsafe-bootstrap -v
-----------------------------------------------------------------------
    WARNING: Elasticsearch MUST be stopped before running this tool.

You should run this tool only if you've lost the majority of master eligible nodes.
If you have a backup, restore from the backup instead.
Running this tool should be the last resort.
Running this tool may cause arbitrary data loss and may render your cluster completely non functional.
Do you accept this risk?

Confirm [y/N] y
Checking node.master setting
Obtaining lock for node
Loading node metadata
Current nodeId is Dtm_EDAQTo-2QmnWGmmYvg
Loading manifest file
Loading global metadata file
New coordination metadata is constructed CoordinationMetaData{term=1, lastCommittedConfiguration=VotingConfiguration{Dtm_EDAQTo-2QmnWGmmYvg}, lastAcceptedConfiguration=VotingConfiguration{Dtm_EDAQTo-2QmnWGmmYvg}, votingConfigExclusions=[]}
Writing new global metadata to disk
Writing new manifest file to disk
Cleaning up old metadata
Master node was successfully bootstrapped
----

[WARNING]
When you run the tool it will make sure that the node being bootstrapped is
stopped. There is no way for this tool to understand if other master eligible
nodes are stopped, please make sure you shut them down.

[NOTE]
`Master node was successfully bootstrapped` does not mean that there would be
 no data loss, it just means that tool was able to complete its job.

[float]
=== Detach cluster
To be described
