[role="xpack"]
[[logs-api]]
== Log ingestion API

experimental::[]

Provides a simple JSON API to ingest log events into {es}.

[discrete]
[[logs-api-request]]
=== {api-request-title}

`POST /_logs`

`POST /_logs/<dataset>`

`POST /_logs/<dataset>/<namespace>`

[discrete]
[[logs-api-prereqs]]
=== {api-prereq-title}
* If the {es} {security-features} are enabled, you must have the `create`
<<privileges-list-indices,index privileges>> for the target data stream.
* Automatic data stream creation requires a matching index template with data
stream enabled. See <<set-up-a-data-stream>>.

[discrete]
[[logs-api-desc]]
=== {api-description-title}

Provides a way to ingest multiple log events into {es}, similar to the <<docs-bulk, Bulk API>>.

The log events are specified in the request body using a newline delimited JSON (NDJSON) structure.

The events are indexed into the `logs-<dataset>-<namespace>` <<data-streams, data stream>>,
according to the dataset and namespace parameters, which can be provided globally or on a per-event basis.

The endpoint is designed in a way that logs are never dropped, as long as the cluster has enough capacity.

If an error happens during ingestion,
the logs are sent to the `logs-dlq-<namespace>` data stream that acts as a dead letter queue for failed events.
However, log ingestion should rarely fail as the default mappings for the `logs-*-*` data streams are designed to minimize mapping conflicts.

A <<logs-api-request-body, couple of fields>> from the {ecs-ref}[Elastic Common Schema (ECS)] are indexed by default that are commonly used to search or filter logs.
All other fields are not indexed by default.
But you can still add any top-level fields and use them in searches and aggregations as the default index template for logs
<<dynamic-mapping-runtime-fields, maps dynamic fields as runtime fields>>.
If there are custom fields that you frequently use in searches or aggregations,
you can add them to the index template for your dataset (`logs-<dataset>-*`) so that the field will be indexed for new data.
This comes at the expense of a larger index size more processing at ingest time.

All fields, aside from the `@timestamp` field, are configured to <<ignore-malformed, ignore malformed>> values.
This means that if a log event contains a field whose type is incompatible with the type of the field that exists in the mapping,
{es} will ignore the field instead of rejecting the whole document.
For example, when a string is provided for a field that is mapped to integer.
Note that this currently doesn't apply for object/scalar mismatches, such as `"foo": "bar"` vs `"foo.bar": "baz"`.

[discrete]
[[logs-api-path-params]]
=== {api-path-parms-title}

{ecs-ref}/ecs-data_stream.html#field-data-stream-dataset[`data_stream.dataset`]::
  (Optional, string)
  Defaults to `generic`.
  Describes the ingested data and its structure.
  It is highly recommended to provide a value for this so that you can add structure to your logs after the fact.
  Example: `nginx.access`.

{ecs-ref}/ecs-data_stream.html#field-data-stream-namespace[`data_stream.namespace`]::
  (Optional, string)
  Defaults to `default`.
  A user-configurable arbitrary grouping, such as an environment (dev, prod, or qa), a team, or a strategic business unit.

[discrete]
[[logs-api-query-params]]
=== {api-query-parms-title}

Any provided query parameter will be added to each log line.
For example, `/_logs?service.name=myapp` will add `"service.name": "myapp"` to all logs.
[discrete]
[[logs-api-request-body]]
=== {api-request-body-title}
The request body contains a newline-delimited list of log events to ingest.
The individual events don't have any required fields and can contain arbitrary JSON content.
There is no required structure for the log events, and you can add any top-level fields.
However, it is recommended to follow the {ecs-ref}[Elastic Common Schema (ECS)] to structure your logs.

TIP: Use the {ecs-logging-ref}/intro.html[ECS logging libraries] to create ECS-compliant JSON logs.

Only the following fields, which are commonly used for searching, filtering, and correlating logs, are indexed by default:

* {ecs-ref}/ecs-base.html#field-timestamp[`@timestamp`] +
  If not provided, will be set to the current time.
* {ecs-ref}/ecs-data_stream.html#field-data-stream-dataset[`data_stream.dataset`] +
  Overrides the `data_stream.dataset` <<logs-api-path-params, path parameter>> on a per-event basis.
* {ecs-ref}/ecs-data_stream.html#field-data-stream-namespace[`data_stream.namespace`] +
  Overrides the `data_stream.namespace` <<logs-api-path-params, path parameter>> on a per-event basis.
* {ecs-ref}/ecs-base.html#field-message[`message`]
* {ecs-ref}/ecs-log.html#field-log-level[`log.level`]
* {ecs-ref}/ecs-log.html#field-log-logger[`log.logger`]
* {ecs-ref}/ecs-service.html#field-service-name[`service.name`]
* {ecs-ref}/ecs-service.html#field-service-environment[`service.environment`]
* {ecs-ref}/ecs-service.html#field-service-version[`service.version`]
* {ecs-ref}/ecs-tracing.html#field-trace-id[`trace.id`]
* {ecs-ref}/ecs-tracing.html#field-transaction-id[`transaction.id`]
* {ecs-ref}/ecs-tracing.html#field-span-id[`span.id`]
* {ecs-ref}/ecs-process.html#field-process-pid[`process.pid`]
* {ecs-ref}/ecs-process.html#field-process-thread-name[`process.thread.name`]
* {ecs-ref}/ecs-error.html#field-error-type[`error.type`]
* {ecs-ref}/ecs-error.html#field-error-message[`error.message`]
* {ecs-ref}/ecs-event.html#field-event-dataset[`event.dataset`]
* {ecs-ref}/ecs-cloud.html#field-cloud-provider[`cloud.provider`]
* {ecs-ref}/ecs-cloud.html#field-cloud-availability-zone[`cloud.availability_zone`]
* {ecs-ref}/ecs-cloud.html#field-cloud-region[`cloud.region`]
* {ecs-ref}/ecs-host.html#field-host-hostname[`host.hostname`]
* {ecs-ref}/ecs-host.html#field-host-name[`host.name`]
* {ecs-ref}/ecs-container.html#field-container-id[`container.id`]
* {ecs-ref}/ecs-container.html#field-container-name[`container.name`]
* {ecs-ref}/ecs-orchestrator.html#field-orchestrator-namespace[`orchestrator.namespace`]
* {ecs-ref}/ecs-orchestrator.html#field-orchestrator-cluster-id[`orchestrator.cluster.id`]
* {ecs-ref}/ecs-orchestrator.html#field-orchestrator-cluster-name[`orchestrator.cluster.name`]
* {ecs-ref}/ecs-orchestrator.html#field-orchestrator-resource-id[`orchestrator.resource.id`]
* {ecs-ref}/ecs-orchestrator.html#field-orchestrator-resource-name[`orchestrator.resource.name`]

Dotted field names are expanded to objects so that they can be used interchangeably with nested objects. For example, the following documents are treated equally: `{"log.level": "INFO"}`, `{"log": { "level": "INFO"} }`.

`_metadata`::
(Optional, object)
Marks this line as a metadata line.
Provides metadata that will be merged into subsequent events.
If a metadata event is provided as the first line, the metadata is added to all logs events.
If a metadata event is provided after the first line, the metadata is added to all subsequent log events until another metadata event is provided.
This way you can easily add global metadata and send logs from multiple datasets in a single request, providing dataset-specific metadata.

[discrete]
[[logs-api-response-body]]
==== {api-response-body-title}

The log API's response body is always empty.

Status

* 202 Accepted: The log events have been received and are processed in the background. They should be searchable after a short while.
* 500 Internal Server Error: There was an error while processing the log events. Some logs may have been lost.

[discrete]
[[logs-api-example]]
=== {api-examples-title}

Ingests a single log into the `logs-myapp-default` data stream.
Provides global metadata via query parameters.

[source,console]
------------------------------------------------------------
POST _logs/myapp?service.name=myapp
{"@timestamp": "2016-05-23T08:05:34.853Z", "message": "Hello World", "custom_field": "value"}
------------------------------------------------------------

After a short while the logs will become searchable.
Event though `custom_field` is not among the <<logs-api-request-body, list of fields that are indexed by default>>,
you can use it in searches and aggregations via <<dynamic-mapping-runtime-fields, dynamically mapped runtime fields>>.

[source,console]
------------------------------------------------------------
POST logs-myapp-default/_search?q=custom_field:value
------------------------------------------------------------
// TEST[continued]
// TEST[s/^/POST logs-myapp-default\/_refresh\n/]
// avoid documenting that a _refresh will always be sufficient to make the logs searchable
// in the future, logs may be buffered and asynchronously processed

The API returns the following response:

[source,console-result]
----
{
  "took": 5,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 1.0,
    "hits": [
      {
        "_index": ".ds-logs-foo-default-2016.05.23-000001",
        "_id": "FKgQT4IBWsM7OYMsIp0N",
        "_score": 1.0,
        "_source": {
          "@timestamp": "2016-05-23T08:05:34.853Z",
          "message": "Hello World",
          "custom_field": "value",
          "service": {
            "name": "myapp"
          },
          "data_stream": {
            "type": "logs",
            "dataset": "myapp",
            "namespace": "default"
          }
        }
      }
    ]
  }
}
----
// TESTRESPONSE[s/"took": 5/"took": $body.took/]
// TESTRESPONSE[s/"_index": ".*"/"_index": $body.hits.hits.0._index/]
// TESTRESPONSE[s/"_id": ".*"/"_id": $body.hits.hits.0._id/]
// TESTRESPONSE[s/"_source": \{\n/"_source": \{\n"error_trace": "true",\n/]
// The test system adds an error_trace:true parameter to all requests,
// including the logs API which interprets it as global metadata that's added to every event

'''

Ingests a single log into the `logs-myapp-default` data stream.
Provides global metadata via a metadata event.

[source,console]
------------------------------------------------------------
POST _logs/myapp
{"_metadata": {"service.name": "myapp"}}
{"@timestamp": "2016-05-23T08:05:34.853Z", "message": "Hello World"}
------------------------------------------------------------

'''

Ingests a two log events into the `logs-myapp-default` and `logs-my_other_app-default` data stream, respectively.
Provides metadata via local metadata events.

[source,console]
------------------------------------------------------------
POST _logs
{"_metadata": {}}
{"_metadata": {"data_stream.dataset": "myapp"}}
{"@timestamp": "2016-05-23T08:05:34.853Z", "message": "Hello app"}
{"_metadata": {"data_stream.dataset": "my_other_app"}}
{"@timestamp": "2016-05-23T08:05:34.853Z", "message": "Hello other app"}
------------------------------------------------------------
