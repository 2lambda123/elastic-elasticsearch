[[plugins-reindex]]
=== Reindex Plugin

The reindex plugin adds two APIs:

* `_update_by_query` updates all documents matching a query in place.
* `_reindex` copies documents from one index to another.

These APIs are brothers so they live in the same plugin. Both use
{ref}/search-request-scroll.html[Scroll] and {ref}/docs-bulk.html[Bulk] APIs
to send an index request per document though they may not work that way in the
future. Regardless of how they work internally they will always work **as**
**though** they send an index request per document that matches a scroll.

[float]
==== Installation

This plugin can be installed using the plugin manager:

[source,sh]
----------------------------------------------------------------
sudo bin/plugin install reindex
----------------------------------------------------------------

The plugin must be installed on every node in the cluster, and each node must
be restarted after installation.

[float]
==== Removal

The plugin can be removed with the following command:

[source,sh]
----------------------------------------------------------------
sudo bin/plugin remove reindex
----------------------------------------------------------------

The node must be stopped before removing the plugin.

[[update-by-query-usage]]
==== Using `_update_by_query`

The simplest usage of `_update_by_query` just `touch`es every document in an
index:

[source,js]
--------------------------------------------------
POST /twitter/_update_by_query
--------------------------------------------------
// AUTOSENSE

That will return something like this:

[source,js]
--------------------------------------------------
{
  "took" : 639,
  "updated": 1235,
  "batches": 13,
  "version_conflicts": 2,
  "failures" : [ ]
}
--------------------------------------------------

`_update_by_query` gets a snapshot of the index when it starts and indexes what
it finds using `internal` versioning. That means that if the document changes
between the time when the snapshot was taken and when the index request is
processed then you'll get a version conflict. When the versions match the
document is changed and the version number is incremented.

Version conflicts are just counted and not returned by default. To count them
you must set `conflicts=abort` on the url or `"conflicts": "abort"` in the
request body. If you do then the `failures` element will contain version
conflict information. There is no `conflicts=record` because we number of
conflicts could grow without bounds so its either `abort` or nothing.

Speaking of the `failures` element, it will contain a list of failures if
there are any. The only "optional" sort of failures are version conflicts. All
other failures always cause the operation to abort. While the first failure
causes the abort, it's possible to encounter lots of subsequent failures due to
batching so all failures are reported. Just in case you want them.

It's important to remember that "abort" here doesn't mean "rollback". This
operation isn't atomic. If it fails part way through then its changes have been
made.

Back to the API format, you can limit the copy to a single type. This will only
update `tweet`s from the `twitter` index:

[source,js]
--------------------------------------------------
POST /twitter/tweet/_update_by_query
--------------------------------------------------
// AUTOSENSE

You can limit using the {ref}/query-dsl.html[Query DSL]. This will update
all documents from the `twitter` index for the user `kimchy`:

[source,js]
--------------------------------------------------
POST /twitter/_update_by_query
{
  "query": { <1>
    "term": {
      "user": "kimchy"
    }
  }
}
--------------------------------------------------
// AUTOSENSE

<1> The query must be passed as a value to the `query` key, in the same
way as the {ref}/search-search.html[Search API]. You can also use the `q`
parameter in the same way as the search api.

So far we've only been touching documents. This is useful for picking up new
properties if the mapping has `"dynamic": "false"` but its only half the fun.
`_update_by_query` supports the `script` object to define how to actually
update the document. This will prefix the `user` field with `other` on all of
kimchy's tweets:
[source,js]
--------------------------------------------------
POST /twitter/_update_by_query
{
  "script": {
    "inline": "ctx._source.user = \"other\" + ctx._source.user"
  },
  "query": {
    "term": {
      "user": "kimchy"
    }
  }
}
--------------------------------------------------
// AUTOSENSE

Just as in {ref}/docs-update.html[Update API] you can set `ctx.op = "noop"` if
your script decides that it doesn't have to make any changes. That will cause
`_update_by_query` to omit that document from its updates. Setting `ctx.op` to
anything else is an error. Setting any other field in `ctx` is an error.

This API doesn't allow you to move the documents it touches, just modify their
source. This is intentional! We've made no provisions for removing the document
from its original location.

It's also possible to do this whole thing on multiple indexes and multiple
types at once, just like the search API:

[source,js]
--------------------------------------------------
POST /twitter,blog/tweet,post/_update_by_query
--------------------------------------------------
// AUTOSENSE

And `routing` works, on the off chance that you need it:

[source,js]
--------------------------------------------------
POST /twitter//_update_by_query?routing=1
--------------------------------------------------
// AUTOSENSE


[[reindex-usage]]
==== Using `_reindex`

`_reindex`'s most basic form just copies documents from one index to another.
This will copy documents from `twitter` into `new_twitter`:

[source,js]
--------------------------------------------------
POST /_reindex
{
  "src": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter"
  }
}
--------------------------------------------------
// AUTOSENSE

That will return something like this:

[source,js]
--------------------------------------------------
{
  "took" : 639,
  "updated": 112,
  "batches": 130,
  "version_conflicts": 0,
  "failures" : [ ],
  "created": 12344
}
--------------------------------------------------

The `src` parameter can also be specified as `source` for those that like that
sort of thing. `dest` can also be specified as `destination`.

Just like `_update_by_query`, `_reindex` gets a snapshot of the source index
but its target must be a **different** index so version conflicts are unlikely.
The `dest` element can be configured like the index API to control optimistic
concurrency control. Just leaving out `version_type` (as above) or setting it
to `internal` will cause Elasticsearch to blindly dump documents into the
target, overwriting any that happen to have the same type and id:

[source,js]
--------------------------------------------------
POST /_reindex
{
  "src": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter",
    "version_type": "internal"
  }
}
--------------------------------------------------
// AUTOSENSE

Setting `version_type` to `external` will cause Elasticsearch to preserve the
`version` from the source, create any documents that are missing, and update
any documents that have an older version in the destination index than they do
in the source index:

[source,js]
--------------------------------------------------
POST /_reindex
{
  "src": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter",
    "version_type": "external"
  }
}
--------------------------------------------------
// AUTOSENSE

Settings `op_type` to `create` will cause `_reindex` to only create missing
documents in the target index. All existing documents will cause a version
conflict:

[source,js]
--------------------------------------------------
POST /_reindex
{
  "src": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter",
    "op_type": "create"
  }
}
--------------------------------------------------
// AUTOSENSE

You can cause aborts on version conflicts with:

[source,js]
--------------------------------------------------
POST /_reindex
{
  "conflicts": "abort",
  "src": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter",
    "op_type": "create"
  }
}
--------------------------------------------------
// AUTOSENSE

You can limit the documents by adding a type to the `src` or by adding a query.
This will only copy `tweet`s made by `kimchy` into `new_twitter`:

[source,js]
--------------------------------------------------
POST /_reindex
{
  "src": {
    "index": "twitter",
    "type": "tweet",
    "query": {
      "term": {
        "user": "kimchy"
      }
    }
  },
  "dest": {
    "index": "new_twitter"
  }
}
--------------------------------------------------
// AUTOSENSE

`index` and `type` in `src` can both be lists, allowing you to copy from lots
of sources in one request. This will copy documents from the `tweet` and `post`
types in the `twitter` and `blog` index. It'd include the `post` type in the
`twitter` index and the `tweet` type in the `blog` index. If you want to be
more specific you'll need to use the `query`. It also makes no effort to handle
id collisions. The target index will remain valid but it's not easy to predict
which document will survive because the iteration order isn't well defined.
Just avoid that situation, ok?
[source,js]
--------------------------------------------------
POST /_reindex
{
  "src": {
    "index": ["twitter", "blog"],
    "type": ["tweet", "post"]
  },
  "index": {
    "index": "all_together"
  }
}
--------------------------------------------------
// AUTOSENSE

Its also possible to limit the number of processed documents by setting
`size`. This will only copy a single document from `twitter` to
`new_twitter`:

[source,js]
--------------------------------------------------
POST /_reindex
{
  "size": 1,
  "src": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter"
  }
}
--------------------------------------------------
// AUTOSENSE

If you want a particular set of documents from the twitter index you'll
need to sort. Sorting makes the scroll less efficient but in some contexts
it's worth it. If possible, prefer a more selective query to `size` and `sort`.
This will copy 10000 documents from `twitter` into `new_twitter`:

[source,js]
--------------------------------------------------
POST /_reindex
{
  "size": 10000,
  "src": {
    "index": "twitter",
    "sort": { "date": "desc" }
  },
  "dest": {
    "index": "new_twitter"
  }
}
--------------------------------------------------
// AUTOSENSE

Like `_update_by_query`, `_reindex` supports a script that modifies the
document. Unlike `_update_by_query`, the script is allowed to modify the
document's metadata. This example bumps the version of the source document:

[source,js]
--------------------------------------------------
POST /_reindex
{
  "src": {
    "index": "twitter",
  },
  "dest": {
    "index": "new_twitter",
    "version_type": "external"
  }
  "script": {
    "internal": "if (ctx._source.foo == 'bar') {ctx._version++; ctx._source.remove('foo')}"
  }
}
--------------------------------------------------
// AUTOSENSE

Think of the possibilities! Just be careful! With great power.... Anyway! You
can also change the "_type" and "_id" and even "_index" to change the
destination as much as you need.

Another thing about `version`, setting it to `null` or clearing it from the
`ctx` map is just like not sending the version in an indexing request: it will
cause that document to be overwritten in the target index regardless of the
versioning there.

By default if `_reindex` sees a document with routing then the routing is
preserved unless it's changed by scripting. You can set `routing` on the `dest`
request to change this:

`keep`::

Sets the routing on the bulk request sent for each match to the routing on
the match. The default.

`discard`::

Sets the routing on the bulk request sent for each match to null.

`=<some text>`::

Sets the routing on the bulk request sent for each match to all text after
the `=`.

For example, you can use the following query to copy all documents from
the `src` index with the company name `cat` into the `dest` index with
routing set to `cat`.
[source,js]
--------------------------------------------------
POST /_reindex
{
  "src": {
    "index": "src"
    "query": {
      "match": {
        "company": "cat"
      }
    }
  }
  "index": {
    "index": "dest",
    "routing": "=cat"
  }
}
--------------------------------------------------
// AUTOSENSE


[float]
=== URL Parameters

In addition to the standard parameters like `pretty`, all APIs in this plugin
support `refresh`, `consistency`, and `timeout`.

Sending the `refresh` url parameter will cause all indexes to which the request
wrote to be refreshed. This is different than the Index API's `refresh`
parameter which causes just the shard that received the new data to be indexed.

`consistency` controls how many copies of a shard must respond to each write
request. `timeout` controls how long each write request waits for unavailable
shards to become available. Both work exactly how they work in the
{ref}/docs-bulk.html[Bulk API].

[float]
=== Response body

The JSON response looks like this:

[source,js]
--------------------------------------------------
{
  "took" : 639,
  "updated": 0,
  "batches": 1,
  "version_conflicts": 2,
  "failures" : [ ]
  "created": 123,
}
--------------------------------------------------

`took`::

The number of milliseconds from start to end of the whole operation.

`updated`::

The number of documents that were successfully updated.

`batches`::

The number of scroll responses pulled back by the the `_reindex` or
`_update_by_query`.

`version_conflicts`::

The number of version conflicts that the `_reindex_` or `_update_by_query` hit.

`failures`::

Array of all indexing failures. By default version conflicts are not included
in this list. See `conflicts` for how to get them included.

`created`::

The number of documents that were successfully created. This is not returned by
`_update_by_query` because it isn't allowed to create documents.

[float]
=== Examples

Below are some examples of how you might use this plugin:

==== Pick up a new property

Say you created an index without dynamic mapping, filled it with data, and then
added a mapping value to pick up more fields from the data:

```
curl -XDELETE localhost:9200/test?pretty
curl -XPUT localhost:9200/test?pretty -d '{
  "mappings": {
    "test": {
      "dynamic": false,
      "properties": {
        "text": {"type": "string"}
      }
    }
  }
}'

curl -XPOST 'localhost:9200/test/test?refresh&pretty' -d '{
  "text": "words words",
  "flag": "bar"
}'
curl -XPOST 'localhost:9200/test/test?refresh&pretty' -d '{
  "text": "words words",
  "flag": "foo"
}'
curl -XPUT localhost:9200/test/_mapping/test?pretty -d '{
  "properties": {
    "text": {"type": "string"},
    "flag": {"type": "string", "analyzer": "keyword"}
  }
}'
```

Searching for the data won't find anything:

```
curl -XPOST 'localhost:9200/test/_search?pretty&filter_path=hits.total' -d '{
  "query": {
    "match": {
      "flag": "foo"
    }
  }
}'
# {
#   "hits" : {
#     "total" : 0
#   }
# }
```

But you can issue an `_update_by_query` request to pick up the new mapping:

```
curl -XPOST 'localhost:9200/test/_update_by_query?pretty&refresh'
curl -XPOST 'localhost:9200/test/_search?pretty&filter_path=hits.total' -d '{
  "query": {
    "match": {
      "flag": "foo"
    }
  }
}'
# {
#   "hits" : {
#     "total" : 1
#   }
# }
```

Hurray! Remember that you can do the exact same thing when adding a field to a
multifield.

==== Change the name of a field

`_reindex` can be used to build a copy of an index with renamed fields:

```
curl -XDELETE localhost:9200/test?pretty

curl -XPOST 'localhost:9200/test/test/1?refresh&pretty' -d '{
  "text": "words words",
  "flag": "foo"
}'

curl -XDELETE localhost:9200/test2?pretty
curl -XPOST localhost:9200/_reindex?pretty  -d '{
  "src": {
    "index": "test"
  },
  "dest": {
    "index": "test2"
  },
  "script": {
    "inline": "ctx._source.tag = ctx._source.remove(\"flag\")"
  }
}'
curl localhost:9200/test2/test/1?pretty
```
