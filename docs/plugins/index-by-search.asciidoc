[[plugins-index-by-search]]
=== Index by Search Plugin

The index-by-search plugin adds support for indexing all documents that match
a query. Internally it uses {ref}/search-request-scroll.html[Scroll] and
{ref}/docs-bulk.html[Bulk] APIs much like
{ref}/plugin-delete-by-query[Delete by Query] though it might not use that
implementation in the future. Regardless of how it does its work its safe to
think of it as doing a scroll and then building bulk requests from each batch.

[float]
==== Installation

This plugin can be installed using the plugin manager:

[source,sh]
----------------------------------------------------------------
sudo bin/plugin install index-by-search
----------------------------------------------------------------

The plugin must be installed on every node in the cluster, and each node must
be restarted after installation.

[float]
==== Removal

The plugin can be removed with the following command:

[source,sh]
----------------------------------------------------------------
sudo bin/plugin remove index-by-search
----------------------------------------------------------------

The node must be stopped before removing the plugin.

[[index-by-search-usage]]
==== Using Index-by-Search

The simplest way to use index-by-search is to copy an entire index into another
index. This will copy all documents in the `twitter` index into the
`new_twitter` index:

[source,js]
--------------------------------------------------
POST /_index_by_search
{
  "source": {
    "index": "twitter"
  },
  "index": {
    "index": "new_twitter"
  }
}
--------------------------------------------------
// AUTOSENSE

You can limit the copy to a single type. This will only copy `tweet`s
from the `twitter` index:

[source,js]
--------------------------------------------------
POST /_index_by_search
{
  "source": {
    "index": "twitter",
    "type": "tweet"
  },
  "index": {
    "index": "new_twitter"
  }
}
--------------------------------------------------
// AUTOSENSE

You can limit using the {ref}/query-dsl.html[Query DSL]. This will copy
all documents from the `twitter` index for the user `kimchy` into the
new_twitter index:

[source,js]
--------------------------------------------------
POST /_index_by_search
{
  "source": {
    "index": "twitter",
    "search": {
      "query": { <1>
        "term": {
          "user": "kimchy"
        }
      }
    }
  },
  "index": {
    "index": "new_twitter"
  }
}
--------------------------------------------------
// AUTOSENSE

<1> The query must be passed as a value to the `query` key, in the same
way as the {ref}/search-search.html[search api].

By default the newly indexed documents will have the same type as the
original documents but you can override the type. This will copy all
`tweet`s in the `twitter` index back into the `twitter` index with the
type `chirp`:

[source,js]
--------------------------------------------------
POST /_index_by_search
{
  "source": {
    "index": "twitter",
    "type": "tweet"
  },
  "index": {
    "index": "twitter",
    "type": "chirp"
  }
}
--------------------------------------------------
// AUTOSENSE

`index` and `type` in `source` can be multiple values, allowing you to
copy from lots of sources in one request. This will copy documents from
the `tweet` and `post` types in the `twitter` and `blog` index. Note that
this includes the `post` type in the `twitter` index. If you want to be
more specific you'll need to use the `query`.
[source,js]
--------------------------------------------------
POST /twitter,blog/_index_by_search
{
  "source": {
    "index": ["twitter", "blog"],
    "type": ["tweet", "post"]
  },
  "index": {
    "index": "all_together"
  }
}
--------------------------------------------------
// AUTOSENSE

NOTE: This request makes no effort to prevent writing duplicates so if it
writes two documents with the same type and id then only one will make it.

Its also possible to limit the number of processed documents by setting
`size`. This will only copy a single document from `twitter` to
`new_twitter`:

[source,js]
--------------------------------------------------
POST /_index_by_search
{
  "size": 1,
  "source": {
    "index": "twitter"
  },
  "index": {
    "index": "new_twitter"
  }
}
--------------------------------------------------
// AUTOSENSE

If you want a particular set of documents from the twitter index you'll
need to sort. Sorting makes the scroll less efficient but in some contexts
its worth it. This will copy 10000 documents from `twitter` into
`new_twitter`:

[source,js]
--------------------------------------------------
POST /_index_by_search
{
  "size": 10000,
  "source": {
    "index": "twitter"
    "search": {
      "sort": { "date": "desc" }
    }
  },
  "index": {
    "index": "new_twitter"
  }
}
--------------------------------------------------
// AUTOSENSE

[float]
=== Query-string parameters

This request supports no query string parameters beyond the standard
parameters like `pretty`.

[float]
=== Preserving external versioning

You can preserve the version numbers of the documents by specifying
`"version_type": "external"` on the `index` portion of the body. This is
most important if your documents were created with
`version_type=external`. Example:
[source,js]
--------------------------------------------------
POST /_index_by_search
{
  "source": {
    "index": "src"
  }
  "index": {
    "index": "dest",
    "version_type": "external"
  }
}
--------------------------------------------------
// AUTOSENSE

[float]
=== Routing

By default if the documents returned by the search have a routing then the
routing is preserved. You can set `routing` on the `index` request to
changes this:

`keep`::

Sets the routing on the bulk request sent for each match to the routing on
the match. The default.

`discard`::

Sets the routing on the bulk request sent for each match to null.

`=<some text>`::

Sets the routing on the bulk request sent for each match to all text after
the `=`.

For example, you can use the following query to copy all documents from
the `src` index with the company name `cat` into the `dest` index with
routing set to `cat`.
[source,js]
--------------------------------------------------
POST /_index_by_search
{
  "source": {
    "index": "src"
    "search": {
      "query": {
        "match": {
          "company": "cat"
        }
      }
    }
  }
  "index": {
    "index": "dest",
    "routing": "=cat"
  }
}
--------------------------------------------------
// AUTOSENSE

[float]
=== Search

You may have noticed the `search` component of the `source` in the
request body and thought "why am I typing this?" The truth is that that
`search` is actually the search that initiates scroll. You can add all
kinds of things to it just like you'd set up a scroll request:

`size`::

The number of hits returned by the
{ref}/search-request-scroll.html[scroll] request. Defaults to 100.

`sort`::

The order in which documents are processed. Defaults to `_doc` for most
efficient scrolling.

Note: `from` is not supported by scroll so its not supported here.

[float]
=== Response body

The JSON response looks like this:

[source,js]
--------------------------------------------------
{
  "took" : 639,
  "timed_out" : false,
  "_indices" : { // NOCOMMIT - we should probably add this
    "_all" : {
      "found" : 5901,
      "deleted" : 5901,
      "missing" : 0,
      "failed" : 0
    },
    "twitter" : {
      "found" : 5901,
      "deleted" : 5901,
      "missing" : 0,
      "failed" : 0
    }
  },
  "failures" : [ ]
}
--------------------------------------------------

Internally, the query is used to execute an initial
{ref}/search-request-scroll.html[scroll] request. As hits are
pulled from the scroll API, they are passed to the {ref}/docs-bulk.html[Bulk
API] for indexing.

NOCOMMIT - this isn't true - we need to be careful with versions but haven't implemented that
IMPORTANT: Index-by-search will only delete the version of the document that
was visible to search at the time the request was executed. Any documents
that have been reindexed or updated during execution will not be deleted.

Since documents can be updated or deleted by external operations during the
_scroll-bulk_ process, the plugin keeps track of different counters for
each index, with the totals displayed under the `_all` index.  The counters
are as follows:

`found`::

The number of documents matching the query for the given index.

`deleted`::

The number of documents successfully deleted for the given index.

`missing`::

The number of documents that were missing when the plugin tried to delete
them. Missing documents were present when the original query was run, but have
already been deleted by another process.

`failed`::

The number of documents that failed to be deleted for the given index. A
document may fail to be deleted if it has been updated to a new version by
another process, or if the shard containing the document has gone missing due
to hardware failure, for example.

[[delete-by-query-plugin-reason]]
==== Why Delete-By-Query is a plugin

The old delete-by-query API in Elasticsearch 1.x was fast but problematic. We
decided to remove the feature from Elasticsearch for these reasons:

Forward compatibility::

    The old implementation wrote a delete-by-query request, including the
    query, to the transaction log.  This meant that, when upgrading to a new
    version, old unsupported queries which cannot be executed might exist in
    the translog, thus causing data corruption.

Consistency and correctness::

    The old implementation executed the query and deleted all matching docs on
    the primary first.  It then repeated this procedure on each replica shard.
    There was no guarantee that the queries on the primary and the replicas
    matched the same document, so it was quite possible to end up with
    different documents on each shard copy.

Resiliency::

    The old implementation could cause out-of-memory exceptions, merge storms,
    and dramatic slow downs if used incorrectly.

[float]
=== New delete-by-query implementation

The new implementation, provided by this plugin, is built internally
using  {ref}/search-request-scroll.html[scroll] to return
the document IDs and versions of all the documents that need to be deleted.
It then uses  the {ref}/docs-bulk.html[`bulk` API] to do the actual deletion.

This can have performance as well as visibility implications. Delete-by-query
now has the following semantics:

non-atomic::

    A delete-by-query may fail at any time while some documents matching the
    query have already been deleted.

try-once::

    A delete-by-query may fail at any time and will not retry it's execution.
    All retry logic is left to the user.

syntactic sugar::

    A delete-by-query is equivalent to a scroll search ordered by `_doc` and
    corresponding bulk-deletes by ID.

point-in-time::

    A delete-by-query will only delete the documents that are visible at the
    point in time the delete-by-query was started, equivalent to the
    scan/scroll API.

consistent::

    A delete-by-query will yield consistent results across all replicas of a
    shard.

forward-compatible::

    A delete-by-query will only send IDs to the shards as deletes such that no
    queries are stored in the transaction logs that might not be supported in
    the future.

visibility::

    The effect of a delete-by-query request will not be visible to search
    until the user refreshes the index, or the index is refreshed
    automatically.

The new implementation suffers from two issues, which is why we decided to
move the functionality to a plugin instead of replacing the feautre in core:

* It is not as fast as the previous implementation. For most use cases, this
  difference should not be noticeable but users running delete-by-query on
  many matching documents may be affected.

* There is currently no way to monitor or cancel a running delete-by-query
  request, except for the `timeout` parameter.

We have plans to solve both of these issues in a later version of Elasticsearch.
