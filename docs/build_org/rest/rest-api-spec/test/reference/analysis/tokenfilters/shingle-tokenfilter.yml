---
"line_31":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: GET
        path: "_analyze"
        body: |
          {
            "tokenizer": "whitespace",
            "filter": [ "shingle" ],
            "text": "quick brown fox jumps"
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens": [
            {
              "token": "quick",
              "start_offset": 0,
              "end_offset": 5,
              "type": "word",
              "position": 0
            },
            {
              "token": "quick brown",
              "start_offset": 0,
              "end_offset": 11,
              "type": "shingle",
              "position": 0,
              "positionLength": 2
            },
            {
              "token": "brown",
              "start_offset": 6,
              "end_offset": 11,
              "type": "word",
              "position": 1
            },
            {
              "token": "brown fox",
              "start_offset": 6,
              "end_offset": 15,
              "type": "shingle",
              "position": 1,
              "positionLength": 2
            },
            {
              "token": "fox",
              "start_offset": 12,
              "end_offset": 15,
              "type": "word",
              "position": 2
            },
            {
              "token": "fox jumps",
              "start_offset": 12,
              "end_offset": 21,
              "type": "shingle",
              "position": 2,
              "positionLength": 2
            },
            {
              "token": "jumps",
              "start_offset": 16,
              "end_offset": 21,
              "type": "word",
              "position": 3
            }
          ]
        }
---
"line_116":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: GET
        path: "_analyze"
        body: |
          {
            "tokenizer": "whitespace",
            "filter": [
              {
                "type": "shingle",
                "min_shingle_size": 2,
                "max_shingle_size": 3
              }
            ],
            "text": "quick brown fox jumps"
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens": [
            {
              "token": "quick",
              "start_offset": 0,
              "end_offset": 5,
              "type": "word",
              "position": 0
            },
            {
              "token": "quick brown",
              "start_offset": 0,
              "end_offset": 11,
              "type": "shingle",
              "position": 0,
              "positionLength": 2
            },
            {
              "token": "quick brown fox",
              "start_offset": 0,
              "end_offset": 15,
              "type": "shingle",
              "position": 0,
              "positionLength": 3
            },
            {
              "token": "brown",
              "start_offset": 6,
              "end_offset": 11,
              "type": "word",
              "position": 1
            },
            {
              "token": "brown fox",
              "start_offset": 6,
              "end_offset": 15,
              "type": "shingle",
              "position": 1,
              "positionLength": 2
            },
            {
              "token": "brown fox jumps",
              "start_offset": 6,
              "end_offset": 21,
              "type": "shingle",
              "position": 1,
              "positionLength": 3
            },
            {
              "token": "fox",
              "start_offset": 12,
              "end_offset": 15,
              "type": "word",
              "position": 2
            },
            {
              "token": "fox jumps",
              "start_offset": 12,
              "end_offset": 21,
              "type": "shingle",
              "position": 2,
              "positionLength": 2
            },
            {
              "token": "jumps",
              "start_offset": 16,
              "end_offset": 21,
              "type": "word",
              "position": 3
            }
          ]
        }
---
"line_220":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: GET
        path: "_analyze"
        body: |
          {
            "tokenizer": "whitespace",
            "filter": [
              {
                "type": "shingle",
                "min_shingle_size": 2,
                "max_shingle_size": 3,
                "output_unigrams": false
              }
            ],
            "text": "quick brown fox jumps"
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens": [
            {
              "token": "quick brown",
              "start_offset": 0,
              "end_offset": 11,
              "type": "shingle",
              "position": 0
            },
            {
              "token": "quick brown fox",
              "start_offset": 0,
              "end_offset": 15,
              "type": "shingle",
              "position": 0,
              "positionLength": 2
            },
            {
              "token": "brown fox",
              "start_offset": 6,
              "end_offset": 15,
              "type": "shingle",
              "position": 1
            },
            {
              "token": "brown fox jumps",
              "start_offset": 6,
              "end_offset": 21,
              "type": "shingle",
              "position": 1,
              "positionLength": 2
            },
            {
              "token": "fox jumps",
              "start_offset": 12,
              "end_offset": 21,
              "type": "shingle",
              "position": 2
            }
          ]
        }
---
"line_298":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: PUT
        path: "my-index-000001"
        body: |
          {
            "settings": {
              "analysis": {
                "analyzer": {
                  "standard_shingle": {
                    "tokenizer": "standard",
                    "filter": [ "shingle" ]
                  }
                }
              }
            }
          }
  - is_false: _shards.failures
---
"line_374":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: GET
        path: "_analyze"
        body: |
          {
            "tokenizer": "whitespace",
            "filter": [
              {
                "type": "stop",
                "stopwords": [ "a" ]
              },
              {
                "type": "shingle",
                "filler_token": "+"
              }
            ],
            "text": "fox jumps a lazy dog"
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens" : [
            {
              "token" : "fox",
              "start_offset" : 0,
              "end_offset" : 3,
              "type" : "word",
              "position" : 0
            },
            {
              "token" : "fox jumps",
              "start_offset" : 0,
              "end_offset" : 9,
              "type" : "shingle",
              "position" : 0,
              "positionLength" : 2
            },
            {
              "token" : "jumps",
              "start_offset" : 4,
              "end_offset" : 9,
              "type" : "word",
              "position" : 1
            },
            {
              "token" : "jumps +",
              "start_offset" : 4,
              "end_offset" : 12,
              "type" : "shingle",
              "position" : 1,
              "positionLength" : 2
            },
            {
              "token" : "+ lazy",
              "start_offset" : 12,
              "end_offset" : 16,
              "type" : "shingle",
              "position" : 2,
              "positionLength" : 2
            },
            {
              "token" : "lazy",
              "start_offset" : 12,
              "end_offset" : 16,
              "type" : "word",
              "position" : 3
            },
            {
              "token" : "lazy dog",
              "start_offset" : 12,
              "end_offset" : 20,
              "type" : "shingle",
              "position" : 3,
              "positionLength" : 2
            },
            {
              "token" : "dog",
              "start_offset" : 17,
              "end_offset" : 20,
              "type" : "word",
              "position" : 4
            }
          ]
        }
---
"line_488":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: PUT
        path: "my-index-000001"
        body: |
          {
            "settings": {
              "analysis": {
                "analyzer": {
                  "en": {
                    "tokenizer": "standard",
                    "filter": [ "my_shingle_filter" ]
                  }
                },
                "filter": {
                  "my_shingle_filter": {
                    "type": "shingle",
                    "min_shingle_size": 2,
                    "max_shingle_size": 5,
                    "output_unigrams": false
                  }
                }
              }
            }
          }
  - is_false: _shards.failures
