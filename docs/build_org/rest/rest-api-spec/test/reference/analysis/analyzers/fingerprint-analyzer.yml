---
"line_19":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: POST
        path: "_analyze"
        body: |
          {
            "analyzer": "fingerprint",
            "text": "Yes yes, Gödel said this sentence is consistent and."
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens": [
            {
              "token": "and consistent godel is said sentence this yes",
              "start_offset": 0,
              "end_offset": 52,
              "type": "fingerprint",
              "position": 0
            }
          ]
        }
---
"line_89":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: PUT
        path: "my-index-000001"
        body: |
          {
            "settings": {
              "analysis": {
                "analyzer": {
                  "my_fingerprint_analyzer": {
                    "type": "fingerprint",
                    "stopwords": "_english_"
                  }
                }
              }
            }
          }
  - is_false: _shards.failures
  - do:
      raw:
        method: POST
        path: "my-index-000001/_analyze"
        body: |
          {
            "analyzer": "my_fingerprint_analyzer",
            "text": "Yes yes, Gödel said this sentence is consistent and."
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens": [
            {
              "token": "consistent godel said sentence yes",
              "start_offset": 0,
              "end_offset": 52,
              "type": "fingerprint",
              "position": 0
            }
          ]
        }
---
"line_159":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: PUT
        path: "fingerprint_example"
        body: |
          {
            "settings": {
              "analysis": {
                "analyzer": {
                  "rebuilt_fingerprint": {
                    "tokenizer": "standard",
                    "filter": [
                      "lowercase",
                      "asciifolding",
                      "fingerprint"
                    ]
                  }
                }
              }
            }
          }
  - is_false: _shards.failures

  - compare_analyzers: {index: fingerprint_example, first: fingerprint, second: rebuilt_fingerprint}

