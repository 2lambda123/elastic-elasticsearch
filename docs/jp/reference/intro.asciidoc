[[elasticsearch-intro]]
= Elasticsearchイントロダクション
[partintro]
--
_**検索（と分析）に向けて**_

{es} は、 {stack} の中核である分散検索および分析エンジンです。 
{ls} と {beats} は、データの収集、集計を行い、 {es} に格納する機能を持ちます。 
{kib} を使うと、インタラクティブなデータ探索、可視化、知見の共有、スタックの管理および監視ができます。 
このようにデータのインデックス作成、検索、および分析に優れた機能を有します。

{es} は、あらゆる種類のデータのリアルタイム検索と分析を提供します。
例えば、{es} は構造化テキスト、非構造化テキスト、数値データ、地理データのいずれのデータに対しても、
効率的な保存およびインデックス付けが可能で、高速検索をサポートしています。
シンプルなデータ収集や集計よりも高度にデータの傾向やパターンを発見できます。
{es} は分散構成を取れるため、データとクエリの量が増えた場合、シームレスなデプロイ拡張が可能です。

検索の問題に限らず、以下に挙げるような様々なユースケースで
データを処理するための速度と柔軟性を{es} は提供します。

* アプリやWebサイトに検索ボックスを追加する
* ログ、メトリクス、セキュリティイベントデータの保存と分析をする
* 機械学習により、データの振る舞いを自動的かつリアルタイムにモデル化する
* ビジネスワークフローを自動化するために、{es} をストレージエンジンとして使用する
* {es} を地理情報システム(GIS)として使用し、空間情報の管理、統合、分析を行う
* {es} をバイオインフォマティクスの研究ツールとして使用し、遺伝データを保存、処理する

我々は、検索が次々と新しい用途で利用されていることを知っています。
それが上記ユースケースのいずれかに類似する場合でも、
全く新しい用途に{es} を利用する場合でも、
{es}のデータ、ドキュメント、およびインデックスを操作する方法は同じです。
--

[[documents-indices]]
== データの保存: ドキュメントとインデックス

{es} は、分散処理型のドキュメントストアです。
{es} は、情報をテーブル式ではなくJSONドキュメントとしてシリアライズすることで、複雑なデータ構造を保存できます。
クラスタ内に複数の {es} ノードを作成すると、ドキュメントはクラスタ全体に分散して保存され、
全てのノードから即座にアクセス可能になります。

ドキュメントが保存されると、ほぼリアルタイム（1秒以内）でインデックスが作成され、検索可能になります。 
{es} は、転置索引と呼ばれるデータ構造を採用しており、非常に高速な全文検索が可能です。
転置索引は、ドキュメント中の全単語をリスト化し、各単語を含む全ドキュメントを識別しています。

インデックスは、最適化されたドキュメントの集まりと言えます。
また、ドキュメントは、キーとバリュー（データの値）のペアであるフィールドの集まりです。
デフォルトでは、{es} は全フィールドの全データにインデックス付けし、
インデックス付けされた各フィールドは最適化された特定のデータ構造になります。
たとえば、テキストフィールドは転置索引に格納され、数値および地理フィールドはBKDツリーに格納されます。 
これも、{es} での検索を非常に高速にしている要因です。

{es} にはスキーマレスの機能もあります。
つまり、ドキュメント内に出現しうる各フィールドの処理方法を明示的に指定しなくとも、
ドキュメントをインデックス付けできます。
動的マッピングが有効な場合、{es} は自動的に新しいフィールドを検出し、インデックスに追加します。
このデフォルトの動作により、データのインデックス作成と探索が簡単になります。
ドキュメントのインデックス作成を開始するだけで、{es} はブール値、浮動小数点値、整数値、日付、文字列を検出して
適切な{es} データ型にマッピングします。

ただし、結局のところ、データについてはデータの所有者自身が最も良く理解していることでしょう。
自身でデータの処理方法を決めたい場合には、動的マッピングの制御ルールの定義や、明示的な独自マッピングの定義により、
フィールドの格納およびインデックス付けの仕方を制御できます。

独自マッピングを定義すると、次のことが可能になります。

* 単なる文字列と正規の値を判別する
* 言語別のテキスト分析を実行する
* 部分一致検索のためにフィールドを最適化する
* カスタム日付形式を使用する
* geo_pointやgeo_shapeなどの自動検出できないデータ型を使用する

多くの場合、同じフィールドをさまざまな目的でさまざまな方法でインデックス付けすると便利です。
たとえば、文字列フィールドに、フルテキスト検索用のテキストフィールドと、
データの並べ替えまたは集計用のキーワードフィールドの両方としてインデックスを作成できます。
または、複数の言語アナライザーを使用して、ユーザー入力を含む文字列フィールドの内容を処理することもできます。

インデックス作成中にフルテキストフィールドに適用される分析チェーンは、検索時にも使用されます。
フルテキストフィールドにクエリを実行すると、クエリテキストは同じ分析を受けてから、用語がインデックスで検索されます。

1つのフィールドを複数の方法でインデックス付けしておくと、異なる様々な目的で利用できるため便利です。
例えば、1つの文字列フィールドを、全文検索用のテキストフィールドとソートや集計用のキーワードフィールドの両方にインデックス付けできます。
また、ユーザー入力による文字列フィールドを、複数の言語アナライザーに通して処理することも可能です。

全文フィールドをインデックス付けする際に適用した分析チェーンは、検索時にも使用されます。
つまり、全文フィールドに検索クエリを実行したとき、クエリ文に同じ分析チェーンが適用された後で用語検索されます。

[[search-analyze]]
== 情報の取得: 検索と分析

{es} の本当の力は検索機能を使うことで得られます。
{es} は、Apache Luceneを検索基盤としており、その全機能に簡単にアクセスできます。

{es} が提供するシンプルで一貫性のあるREST APIが、クラスタ管理やデータのインデックス作成・検索を可能とします。
直接コマンドラインから、または {kib} のDeveloperコンソールからAPIリクエストを送信することで、簡単にテストできます。
独自のアプリケーションから利用する場合は、
好みの言語（Java、JavaScript、Go、.NET、PHP、Perl、Python、Ruby）で
https://www.elastic.co/guide/en/elasticsearch/client/index.html[{es} クライアント]
が利用できます。

[float]
[[search-data]]
=== データの検索

{es} REST APIは、構造化クエリ、全文クエリ、およびこの2つを組み合わせたクエリをサポートしています。
構造化クエリは、SQLで構成されたクエリに似ています。
例えば、 `employee` インデックスから `gender` と `age` フィールドで検索して、
結果を `hire_date` フィールドでソートするといったことができます。
全文クエリは、クエリ文にマッチする全てのドキュメントを検索し、結果を _relevance_ でソートして返します。
_relevance_ は、検索語にどれほどマッチしているかを示す値です。

個々の用語検索に加えて、フレーズ検索、類似検索、先頭検索もできます。さらに、オートコンプリートの提示機能もあります。

{es} は、非テキストデータも最適なデータ構造で保存するため、
地理データやその他の数値データに対しても、高パフォーマンスにクエリを実行できます。

{es} の全検索機能にアクセスするために、
JSON形式のクエリ言語（<<query-dsl, Query DSL>>）を使います。
または、ネイティブな方法（<<sql-overview, SQL形式のクエリ>>）も利用できます。
SQLを通して、様々なサードパーティーのアプリケーション内で {es} と連携するための、
JDBC、ODBCドライバーも利用できます。

[float]
[[analyze-data]]
=== データの分析

データの主要メトリクス、パターン、傾向を知るためにデータ要約を作成するには、{es} 集計が使えます。
「干し草の中から針を探す」という諺がありますが、これに反して、次のような問題に回答できるようになります。

* 干し草の中に何本の針がありますか？
* 針の平均長は？
* メーカー別の針の長さの中央値は？
* 過去6か月間で1月に何本ずつ針が干し草の中に加えられましたか？

以下のようなより難しい問題にも答えられます。

* 最も人気のある針メーカーはどこですか？
* 異常な針はありますか？

集計は検索と同じデータ構造を用いるため、とても高速です。
なので、リアルタイムにデータ分析・可視化ができます。
レポートやダッシュボードもデータに合わせて更新されるため
常に最新の情報を使ってアクションを実行できます。

さらに、集計は検索に引き続いて実行できます。つまり、1つのリクエストで
ドキュメント検索、フィルター、分析を一度に実行できます
特定の検索結果に引き続いて集計がされるため、
検索条件にマッチする集計結果を取得できます。
たとえば、単にサイズ70の針の数だけでなく、
サイズ70で、付着防止加工がされた刺繍用（_non-stick embroidery_）の針の数を取得できます。

[float]
[[more-features]]
==== まだまだ機能があります

時系列データの分析を自動化したい場合は、
{stack-ov}/ml-overview.html[機械学習] 機能を使ってみましょう。
正常動作としてのベースラインが作成され、異常パターンを検知できます。
機械学習を使用すると、以下を検出できます。

* 値、カウント、頻度の時間的な偏差に関する異常値
* 統計的希少性
* 集団メンバーの異常行動

素晴らしいことに、これを実行するのに、アルゴリズムやモデルの指定、その他の統計関連の設定は不要です。

[[scalability]]
== スケーラビリティと復元性: クラスタ、ノード、シャード
++++
<titleabbrev>Scalability and resilience</titleabbrev>
++++

{es} は常に利用できるよう、また必要に応じてスケールできるよう、ネイティブで分散構成をサポートしています。
サーバー（ノード）をクラスタに追加することでキャパシティを増加でき、
{es} が自動的にデータやクエリ負荷を全ノードに対して分散します。
アプリケーションに対して修正を施す必要はありません。{es} がマルチノードクラスタをバランスして、
スケーリングや高い可用性を提供してくれます。ノードは多いほど良いです。

これの仕組みですが、
{es} インデックスは、1つ以上の物理シャードの論理的なグループであり、
各物理シャードは、実際には独立したインデックスを持っています。
インデックス内のドキュメントを複数シャードに分散し、それらシャードを複数のノードに分散することで、
{es} は冗長性を確保でき、ハードウェア障害から保護、また、ノードがクラスタに追加される度にキャパシティを増加できます。
クラスターが拡大（または縮小）すると、{es} が自動的にシャードを移転して、クラスターのバランスを調整します。

シャードには、プライマリとレプリカの2種類があります。インデックス内の各ドキュメントは必ず1つのプライマリシャードに属します。
レプリカシャードはプライマリシャードの複製であり、データの冗長コピーを作ることで、
ハードウェア障害からの保護、ドキュメント検索や取得といった読み込みリクエストのためのキャパシティ増加ができます。

インデックスのプライマリシャードの数は、インデックス作成時に固定されますが、レプリカシャードの数は、インデックス作成やクエリ操作を中断することなく、いつでも変更できます。

[float]
[[it-depends]]
=== シャードの設定はデータ依存

シャードのサイズやプライマリシャードの数はパフォーマンスやトレードオフに
関係するため、よく考えて設定する必要があります。
シャードの数が増えれば、単にインデックスを保持・整備する際のオーバーヘッドが増加します。
シャードのサイズが大きくなれば、
{es} がクラスタの再調整をする際のシャードの移転にかかる時間が増加します

たくさんの小さなシャードに対してクエリを実行する場合、シャードごとの処理は高速になりますが、
クエリが増えればオーバーヘッドも増加します。よって、少しの大きなシャードに対してクエリを実行した方が
高速になる場合もあります。つまるところ、これらの最適な設定はデータやクエリに依存します。

開始地点として:

* シャードサイズの平均が数GBから数十GB内に収まるようにしてください。
  時系列データの場合、シャードサイズは20GBから40GBの範囲になるのが一般的です。

* シャード数が膨大になることは避けましょう。
  1ノードが保持できるシャードの数は利用できるヒープ領域に比例します。
  基本的には、1GBのヒープ領域で20以下のシャード数となることが望ましいです。

最適な設定を見つける一番の近道は、
https://www.elastic.co/elasticon/conf/2016/sf/quantitative-cluster-sizing[ご自身のデータとクエリでテストをする]
ことです。

[float]
[[disaster-ccr]]
=== 災害が発生した場合について

クラスター内のノードは、パフォーマンスの制約から同じネットワーク上に存在しなければなりません。
ノードが異なるデータセンターにあると、クラスター内でシャードの分散を行うのに時間がかかりすぎてしまいます。
ただし、すべてのデータを一か所に集めると、可用性の低いアーキテクチャとなります。
一か所で大規模な障害が発生したとき、シームレスに別拠点のサーバーが引き継げることが必要になります。
それを実現する答えが、{ccr-cap} (CCR)です。

CCR を使うと、プライマリクラスタのホットバックアップとして機能するセカンダリクラスタへ
インデックスを自動的に同期できます。
プライマリクラスタで障害が発生すると、セカンダリクラスタで引き継ぐことができます。
また、セカンダリクラスタを使って近隣地域のユーザーリクエストを処理することもできます。

{ccr-cap} はアクティブ/パッシブです。プライマリクラスタのインデックスは
アクティブリーダーですべての書き込みリクエストを処理します。
セカンダリクラスタのレプリカインデックスは読み込み専用です。

[float]
[[admin]]
=== 長期的な管理

エンタープライズシステムの中で利用する場合、{es} クラスターを保護、管理、監視するツールが必要です。 
{es} には、セキュリティ、監視、管理機能が統合されており、
{kibana-ref}/introduction.html[{kib}]
をクラスター管理のためのコントロールセンターとして使用できます。
<<rollup-overview, データロールアップ>> 
や 
<<index-lifecycle-management, インデックスライフサイクル管理>>
などの機能は、長期間にわたる賢いデータ管理を支援してくれます。