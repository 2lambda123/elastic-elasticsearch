---
"line_59":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: PUT
        path: "my-index-000001"
        body: |
          {
            "settings": {
              "analysis": {
                "analyzer": {
                  "my_custom_analyzer": {
                    "type": "custom",
                    "tokenizer": "standard",
                    "char_filter": [
                      "html_strip"
                    ],
                    "filter": [
                      "lowercase",
                      "asciifolding"
                    ]
                  }
                }
              }
            }
          }
  - is_false: _shards.failures
  - do:
      raw:
        method: POST
        path: "my-index-000001/_analyze"
        body: |
          {
            "analyzer": "my_custom_analyzer",
            "text": "Is this <b>déjà vu</b>?"
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens": [
            {
              "token": "is",
              "start_offset": 0,
              "end_offset": 2,
              "type": "<ALPHANUM>",
              "position": 0
            },
            {
              "token": "this",
              "start_offset": 3,
              "end_offset": 7,
              "type": "<ALPHANUM>",
              "position": 1
            },
            {
              "token": "deja",
              "start_offset": 11,
              "end_offset": 15,
              "type": "<ALPHANUM>",
              "position": 2
            },
            {
              "token": "vu",
              "start_offset": 16,
              "end_offset": 22,
              "type": "<ALPHANUM>",
              "position": 3
            }
          ]
        }
---
"line_159":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: PUT
        path: "my-index-000001"
        body: |
          {
            "settings": {
              "analysis": {
                "analyzer": {
                  "my_custom_analyzer": {
                    "char_filter": [
                      "emoticons"
                    ],
                    "tokenizer": "punctuation",
                    "filter": [
                      "lowercase",
                      "english_stop"
                    ]
                  }
                },
                "tokenizer": {
                  "punctuation": {
                    "type": "pattern",
                    "pattern": "[ .,!?]"
                  }
                },
                "char_filter": {
                  "emoticons": {
                    "type": "mapping",
                    "mappings": [
                      ":) => _happy_",
                      ":( => _sad_"
                    ]
                  }
                },
                "filter": {
                  "english_stop": {
                    "type": "stop",
                    "stopwords": "_english_"
                  }
                }
              }
            }
          }
  - is_false: _shards.failures
  - do:
      raw:
        method: POST
        path: "my-index-000001/_analyze"
        body: |
          {
            "analyzer": "my_custom_analyzer",
            "text": "I'm a :) person, and you?"
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens": [
            {
              "token": "i'm",
              "start_offset": 0,
              "end_offset": 3,
              "type": "word",
              "position": 0
            },
            {
              "token": "_happy_",
              "start_offset": 6,
              "end_offset": 8,
              "type": "word",
              "position": 2
            },
            {
              "token": "person",
              "start_offset": 9,
              "end_offset": 15,
              "type": "word",
              "position": 3
            },
            {
              "token": "you",
              "start_offset": 21,
              "end_offset": 24,
              "type": "word",
              "position": 5
            }
          ]
        }
