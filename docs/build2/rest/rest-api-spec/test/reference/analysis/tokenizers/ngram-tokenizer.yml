---
"line_24":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: POST
        path: "_analyze"
        body: |
          {
            "tokenizer": "ngram",
            "text": "Quick Fox"
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens": [
            {
              "token": "Q",
              "start_offset": 0,
              "end_offset": 1,
              "type": "word",
              "position": 0
            },
            {
              "token": "Qu",
              "start_offset": 0,
              "end_offset": 2,
              "type": "word",
              "position": 1
            },
            {
              "token": "u",
              "start_offset": 1,
              "end_offset": 2,
              "type": "word",
              "position": 2
            },
            {
              "token": "ui",
              "start_offset": 1,
              "end_offset": 3,
              "type": "word",
              "position": 3
            },
            {
              "token": "i",
              "start_offset": 2,
              "end_offset": 3,
              "type": "word",
              "position": 4
            },
            {
              "token": "ic",
              "start_offset": 2,
              "end_offset": 4,
              "type": "word",
              "position": 5
            },
            {
              "token": "c",
              "start_offset": 3,
              "end_offset": 4,
              "type": "word",
              "position": 6
            },
            {
              "token": "ck",
              "start_offset": 3,
              "end_offset": 5,
              "type": "word",
              "position": 7
            },
            {
              "token": "k",
              "start_offset": 4,
              "end_offset": 5,
              "type": "word",
              "position": 8
            },
            {
              "token": "k ",
              "start_offset": 4,
              "end_offset": 6,
              "type": "word",
              "position": 9
            },
            {
              "token": " ",
              "start_offset": 5,
              "end_offset": 6,
              "type": "word",
              "position": 10
            },
            {
              "token": " F",
              "start_offset": 5,
              "end_offset": 7,
              "type": "word",
              "position": 11
            },
            {
              "token": "F",
              "start_offset": 6,
              "end_offset": 7,
              "type": "word",
              "position": 12
            },
            {
              "token": "Fo",
              "start_offset": 6,
              "end_offset": 8,
              "type": "word",
              "position": 13
            },
            {
              "token": "o",
              "start_offset": 7,
              "end_offset": 8,
              "type": "word",
              "position": 14
            },
            {
              "token": "ox",
              "start_offset": 7,
              "end_offset": 9,
              "type": "word",
              "position": 15
            },
            {
              "token": "x",
              "start_offset": 8,
              "end_offset": 9,
              "type": "word",
              "position": 16
            }
          ]
        }
---
"line_220":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: PUT
        path: "my-index-000001"
        body: |
          {
            "settings": {
              "analysis": {
                "analyzer": {
                  "my_analyzer": {
                    "tokenizer": "my_tokenizer"
                  }
                },
                "tokenizer": {
                  "my_tokenizer": {
                    "type": "ngram",
                    "min_gram": 3,
                    "max_gram": 3,
                    "token_chars": [
                      "letter",
                      "digit"
                    ]
                  }
                }
              }
            }
          }
  - is_false: _shards.failures
  - do:
      raw:
        method: POST
        path: "my-index-000001/_analyze"
        body: |
          {
            "analyzer": "my_analyzer",
            "text": "2 Quick Foxes."
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens": [
            {
              "token": "Qui",
              "start_offset": 2,
              "end_offset": 5,
              "type": "word",
              "position": 0
            },
            {
              "token": "uic",
              "start_offset": 3,
              "end_offset": 6,
              "type": "word",
              "position": 1
            },
            {
              "token": "ick",
              "start_offset": 4,
              "end_offset": 7,
              "type": "word",
              "position": 2
            },
            {
              "token": "Fox",
              "start_offset": 8,
              "end_offset": 11,
              "type": "word",
              "position": 3
            },
            {
              "token": "oxe",
              "start_offset": 9,
              "end_offset": 12,
              "type": "word",
              "position": 4
            },
            {
              "token": "xes",
              "start_offset": 10,
              "end_offset": 13,
              "type": "word",
              "position": 5
            }
          ]
        }
