---
"line_15":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: POST
        path: "_analyze"
        body: |
          {
            "tokenizer": "keyword",
            "text": "New York"
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens": [
            {
              "token": "New York",
              "start_offset": 0,
              "end_offset": 8,
              "type": "word",
              "position": 0
            }
          ]
        }
---
"line_61":
  - skip:
      features:
        - default_shards
        - stash_in_key
        - stash_in_path
        - stash_path_replace
        - warnings
  - do:
      raw:
        method: POST
        path: "_analyze"
        body: |
          {
            "tokenizer": "keyword",
            "filter": [ "lowercase" ],
            "text": "john.SMITH@example.COM"
          }
  - is_false: _shards.failures
  - match:
      $body:
        {
          "tokens": [
            {
              "token": "john.smith@example.com",
              "start_offset": 0,
              "end_offset": 22,
              "type": "word",
              "position": 0
            }
          ]
        }
